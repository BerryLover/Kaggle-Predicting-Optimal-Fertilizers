{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91717,"databundleVersionId":12184666,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":1262.816715,"end_time":"2025-06-24T15:17:05.345229","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-06-24T14:56:02.528514","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ncwd = os.getcwd()\nprint(\"Current working directory is {}\".format(cwd))\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_validate, cross_val_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, log_loss\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import make_column_selector as selector\n\nfrom datetime import datetime\nimport joblib\n\nimport lightgbm as lgb\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-06-26T22:45:11.660569Z","iopub.execute_input":"2025-06-26T22:45:11.661093Z","iopub.status.idle":"2025-06-26T22:45:17.039186Z","shell.execute_reply.started":"2025-06-26T22:45:11.661070Z","shell.execute_reply":"2025-06-26T22:45:17.038619Z"},"papermill":{"duration":4.097805,"end_time":"2025-06-24T14:56:11.585016","exception":false,"start_time":"2025-06-24T14:56:07.487211","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s5e6/sample_submission.csv\n/kaggle/input/playground-series-s5e6/train.csv\n/kaggle/input/playground-series-s5e6/test.csv\nCurrent working directory is /kaggle/working\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Data preprocessing","metadata":{"papermill":{"duration":0.004907,"end_time":"2025-06-24T14:56:11.596038","exception":false,"start_time":"2025-06-24T14:56:11.591131","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def sort_columns(df):\n    return df.sort_index(axis=1)\n\ndef describe_data(df):\n    ## Basic statistics\n    describe = df.describe(include='all')\n    info = df.info()  # Return None, print df.info() directly to console.\n    null_count = df.isnull().sum()\n    ## Unique values\n    unique_count = df.nunique()\n    sample_size = df.shape[0]\n    unique_ratio = unique_count / sample_size\n    ## print data descriptions\n    print(\"\\n====== df:\\n\")\n    print(df)\n    print(\"\\n====== describe:\\n\")\n    print(describe)\n    print(\"\\n======info: \\n\")\n    print(df.info())\n    print(\"\\n====== null_count: \\n\")\n    print(null_count)\n    print(\"\\n====== unique_count: \\n\")\n    print(unique_count)\n    print(\"\\n====== unique_ratio: \\n\")\n    print(unique_ratio)\n\n    data_description = {\n        \"describe\": describe,\n        \"info\": info,\n        \"null_count\": null_count,\n        \"unique_count\": unique_count,\n        \"sample_size\": sample_size,\n        \"unique_ratio\": unique_ratio\n    }\n    return data_description\n\ndef drop_columns(df, cols_to_drop):\n    df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n    return df   \n\ndef intersect_train_test_columns(train_df, test_df):\n    ## Find common columns between train and test\n    common_cols = train_df.columns.intersection(test_df.columns)\n    ## Keep only those columns\n    train_aligned = train_df[common_cols].copy()\n    test_aligned = test_df[common_cols].copy()\n    return train_aligned, test_aligned\n\n######\n## Don't ever use dummies for one-hot encoding. Big issue when doing online prediction with new data.\n## pd.get_dummies() will mess up the one-hot positions.\n## Use OneHotEncoder from scikit-learn instead.\n######\n# def category_to_onehot(df, **kwargs):\n#     return pd.get_dummies(df, **kwargs)\n\ndef transform_numeric_to_category(df):\n    for col in df.select_dtypes(include=['int64', 'float64']).columns:\n        df[col] = df[col].astype('category')\n    return df\n\ndef build_label_encoders(train_df):\n    '''\n    LabelEncoder is strictly meant for 1D arrays (i.e., one column at a time). \n    It doesn’t support fitting across a 2D DataFrame of multiple categorical columns\n    '''\n    cat_cols = train_df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n    encoders = dict()\n    for col in cat_cols:\n        le = LabelEncoder()\n        train_df[col] = train_df[col].astype(str)  # Ensure consistent type\n        le.fit(train_df[col])\n        encoders[col] = le\n    return encoders\n\ndef build_onehot_encoder(train_df):\n    cat_cols = train_df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n    encoder = ColumnTransformer(\n        transformers=[\n            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols)\n        ],\n        remainder='passthrough'\n    )\n    encoder.fit(train_df)\n    return encoder\n\ndef mapk(y_true, y_pred_probs, k=3, labels=None):\n    \"\"\"\n    Compute Mean Average Precision at K (MAP@k).\n\n    Parameters:\n    - y_true: array-like of shape (n_samples,) – true labels (can be str or int)\n    - y_pred_probs: array-like of shape (n_samples, n_classes) – predicted class probabilities\n    - k: int – number of top predictions to consider\n    - labels: list – ordered list of label names corresponding to columns in y_pred_probs\n\n    Returns:\n    - map_k: float – MAP@k score\n    \"\"\"\n    if labels is None:\n        raise ValueError(\"You must provide a list of label names in `labels` to map predicted indices to class names.\")\n\n    top_k_preds = np.argsort(-y_pred_probs, axis=1)[:, :k]  # Get top-k predicted indices\n    y_true = np.asarray(y_true)\n\n    score = 0.0\n    for i in range(len(y_true)):\n        true_label = y_true[i]\n        predicted_labels = [labels[idx] for idx in top_k_preds[i]]\n\n        if true_label in predicted_labels:\n            rank = predicted_labels.index(true_label)\n            score += 1.0 / (rank + 1)\n\n    return score / len(y_true)","metadata":{"execution":{"iopub.status.busy":"2025-06-26T22:45:17.040349Z","iopub.execute_input":"2025-06-26T22:45:17.040966Z","iopub.status.idle":"2025-06-26T22:45:17.052546Z","shell.execute_reply.started":"2025-06-26T22:45:17.040943Z","shell.execute_reply":"2025-06-26T22:45:17.051801Z"},"papermill":{"duration":0.018318,"end_time":"2025-06-24T14:56:11.619595","exception":false,"start_time":"2025-06-24T14:56:11.601277","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Parameter settings\nlabels = [\"Fertilizer Name\"]\ntimestamp = datetime.now().strftime('%Y%m%d')\noutput_pred_num = 3\n\n# Read inputs\ntrain_df = pd.read_csv(\"../input/playground-series-s5e6/train.csv\")\ntrain_df_src = train_df.copy()\ntest_df = pd.read_csv(\"../input/playground-series-s5e6/test.csv\")\ntest_df_src = test_df.copy()\nsample_df = pd.read_csv(\"../input/playground-series-s5e6/sample_submission.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2025-06-26T22:45:17.053238Z","iopub.execute_input":"2025-06-26T22:45:17.053493Z","iopub.status.idle":"2025-06-26T22:45:18.455872Z","shell.execute_reply.started":"2025-06-26T22:45:17.053476Z","shell.execute_reply":"2025-06-26T22:45:18.455332Z"},"papermill":{"duration":1.646191,"end_time":"2025-06-24T14:56:13.269202","exception":false,"start_time":"2025-06-24T14:56:11.623011","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# train_df\n# test_df_src\nsample_df.iloc[0, 1]\n","metadata":{"execution":{"iopub.status.busy":"2025-06-26T22:45:18.457595Z","iopub.execute_input":"2025-06-26T22:45:18.457996Z","iopub.status.idle":"2025-06-26T22:45:18.463309Z","shell.execute_reply.started":"2025-06-26T22:45:18.457976Z","shell.execute_reply":"2025-06-26T22:45:18.462641Z"},"papermill":{"duration":0.012205,"end_time":"2025-06-24T14:56:13.284606","exception":false,"start_time":"2025-06-24T14:56:13.272401","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'14-35-14 10-26-26 Urea'"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train_df_src","metadata":{"execution":{"iopub.status.busy":"2025-06-26T22:45:18.464037Z","iopub.execute_input":"2025-06-26T22:45:18.464306Z","iopub.status.idle":"2025-06-26T22:45:18.498046Z","shell.execute_reply.started":"2025-06-26T22:45:18.464283Z","shell.execute_reply":"2025-06-26T22:45:18.497439Z"},"papermill":{"duration":0.035839,"end_time":"2025-06-24T14:56:13.323836","exception":false,"start_time":"2025-06-24T14:56:13.287997","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"            id  Temparature  Humidity  Moisture Soil Type    Crop Type  \\\n0            0           37        70        36    Clayey    Sugarcane   \n1            1           27        69        65     Sandy      Millets   \n2            2           29        63        32     Sandy      Millets   \n3            3           35        62        54     Sandy       Barley   \n4            4           35        58        43       Red        Paddy   \n...        ...          ...       ...       ...       ...          ...   \n749995  749995           25        69        30    Clayey        Maize   \n749996  749996           37        64        58     Loamy    Sugarcane   \n749997  749997           35        68        59     Sandy  Ground Nuts   \n749998  749998           31        68        29       Red       Cotton   \n749999  749999           33        55        29     Loamy       Cotton   \n\n        Nitrogen  Potassium  Phosphorous Fertilizer Name  \n0             36          4            5           28-28  \n1             30          6           18           28-28  \n2             24         12           16        17-17-17  \n3             39         12            4        10-26-26  \n4             37          2           16             DAP  \n...          ...        ...          ...             ...  \n749995         8         16            6           28-28  \n749996        38          8           20        17-17-17  \n749997         6         11           29        10-26-26  \n749998         9         11           12           20-20  \n749999         4         10            9            Urea  \n\n[750000 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Temparature</th>\n      <th>Humidity</th>\n      <th>Moisture</th>\n      <th>Soil Type</th>\n      <th>Crop Type</th>\n      <th>Nitrogen</th>\n      <th>Potassium</th>\n      <th>Phosphorous</th>\n      <th>Fertilizer Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>37</td>\n      <td>70</td>\n      <td>36</td>\n      <td>Clayey</td>\n      <td>Sugarcane</td>\n      <td>36</td>\n      <td>4</td>\n      <td>5</td>\n      <td>28-28</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>27</td>\n      <td>69</td>\n      <td>65</td>\n      <td>Sandy</td>\n      <td>Millets</td>\n      <td>30</td>\n      <td>6</td>\n      <td>18</td>\n      <td>28-28</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>29</td>\n      <td>63</td>\n      <td>32</td>\n      <td>Sandy</td>\n      <td>Millets</td>\n      <td>24</td>\n      <td>12</td>\n      <td>16</td>\n      <td>17-17-17</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>35</td>\n      <td>62</td>\n      <td>54</td>\n      <td>Sandy</td>\n      <td>Barley</td>\n      <td>39</td>\n      <td>12</td>\n      <td>4</td>\n      <td>10-26-26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>35</td>\n      <td>58</td>\n      <td>43</td>\n      <td>Red</td>\n      <td>Paddy</td>\n      <td>37</td>\n      <td>2</td>\n      <td>16</td>\n      <td>DAP</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>749995</th>\n      <td>749995</td>\n      <td>25</td>\n      <td>69</td>\n      <td>30</td>\n      <td>Clayey</td>\n      <td>Maize</td>\n      <td>8</td>\n      <td>16</td>\n      <td>6</td>\n      <td>28-28</td>\n    </tr>\n    <tr>\n      <th>749996</th>\n      <td>749996</td>\n      <td>37</td>\n      <td>64</td>\n      <td>58</td>\n      <td>Loamy</td>\n      <td>Sugarcane</td>\n      <td>38</td>\n      <td>8</td>\n      <td>20</td>\n      <td>17-17-17</td>\n    </tr>\n    <tr>\n      <th>749997</th>\n      <td>749997</td>\n      <td>35</td>\n      <td>68</td>\n      <td>59</td>\n      <td>Sandy</td>\n      <td>Ground Nuts</td>\n      <td>6</td>\n      <td>11</td>\n      <td>29</td>\n      <td>10-26-26</td>\n    </tr>\n    <tr>\n      <th>749998</th>\n      <td>749998</td>\n      <td>31</td>\n      <td>68</td>\n      <td>29</td>\n      <td>Red</td>\n      <td>Cotton</td>\n      <td>9</td>\n      <td>11</td>\n      <td>12</td>\n      <td>20-20</td>\n    </tr>\n    <tr>\n      <th>749999</th>\n      <td>749999</td>\n      <td>33</td>\n      <td>55</td>\n      <td>29</td>\n      <td>Loamy</td>\n      <td>Cotton</td>\n      <td>4</td>\n      <td>10</td>\n      <td>9</td>\n      <td>Urea</td>\n    </tr>\n  </tbody>\n</table>\n<p>750000 rows × 10 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"############\n## Data Cleaning\n############\n\n## Describe data\ntrain_df_description = describe_data(train_df)\n\n## Sort data (Ensuring pd.get_dummies() gives consistent orders on train and test data.)\ntrain_df = sort_columns(train_df)\ntest_df = sort_columns(test_df)\n\n## Drop columns\ncols_to_drop = [\"id\"]\ntrain_df = drop_columns(train_df, cols_to_drop)\ntest_df = drop_columns(test_df, cols_to_drop)\n\n## Split labels from training data\ntrain_feature_df = train_df.drop(columns=labels)\ntrain_label_df = train_df[labels]\n\n## Take the intersection of train and test features.\ntrain_feature_df, test_df = intersect_train_test_columns(train_feature_df, test_df)\n\n############\n## Feature Engineering\n############\n\n## Transform categorical features into label encoding.\nlabel_encoders = build_label_encoders(train_df.copy())\n\ntrain_encoded = train_feature_df.copy()\nfor col, le in label_encoders.items():\n    if col in train_encoded.columns:\n        train_encoded[col] = le.transform(train_encoded[col].astype(str))\n    else:\n        print(f\"Warning: Column '{col}' not found in train_encoded. Skipping...\")\n        \ntest_encoded = test_df.copy()\nfor col, le in label_encoders.items():\n    if col in test_encoded.columns:\n        test_encoded[col] = le.transform(test_encoded[col].astype(str))\n    else:\n        print(f\"Warning: Column '{col}' not found in test_encoded. Skipping...\")\n        \ntrain_label_encoded = train_label_df.copy()\nfor col in train_label_encoded.columns:\n    if col in label_encoders.keys():\n        train_label_encoded[col] = label_encoders[col].transform(train_label_encoded[col].astype(str))\n        print(f\"Train label column '{col}' is encoded with LabelEncoder.\")\n\n## Transform numerical features into categorical features.\ntrain_encoded = transform_numeric_to_category(train_encoded)\ntest_encoded = transform_numeric_to_category(test_encoded)   \n\n# ## Transform categorical features into one-hot encoding.\n# oh_encoder = build_onehot_encoder(train_feature_df)\n\n# train_encoded = pd.DataFrame(\n#     oh_encoder.transform(train_df),\n#     columns=oh_encoder.get_feature_names_out(),\n#     index=train_df.index\n# )\n# test_encoded = pd.DataFrame(\n#     oh_encoder.transform(test_df),\n#     columns=oh_encoder.get_feature_names_out(),\n#     index=test_df.index\n# )\n\n\n# train_encoded = train_encoded.iloc[:200,]\n# train_label_df = train_label_df.iloc[:200]","metadata":{"execution":{"iopub.status.busy":"2025-06-26T22:45:18.498793Z","iopub.execute_input":"2025-06-26T22:45:18.499042Z","iopub.status.idle":"2025-06-26T22:45:20.157831Z","shell.execute_reply.started":"2025-06-26T22:45:18.499020Z","shell.execute_reply":"2025-06-26T22:45:20.157170Z"},"papermill":{"duration":2.623124,"end_time":"2025-06-24T14:56:15.950647","exception":false,"start_time":"2025-06-24T14:56:13.327523","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 750000 entries, 0 to 749999\nData columns (total 10 columns):\n #   Column           Non-Null Count   Dtype \n---  ------           --------------   ----- \n 0   id               750000 non-null  int64 \n 1   Temparature      750000 non-null  int64 \n 2   Humidity         750000 non-null  int64 \n 3   Moisture         750000 non-null  int64 \n 4   Soil Type        750000 non-null  object\n 5   Crop Type        750000 non-null  object\n 6   Nitrogen         750000 non-null  int64 \n 7   Potassium        750000 non-null  int64 \n 8   Phosphorous      750000 non-null  int64 \n 9   Fertilizer Name  750000 non-null  object\ndtypes: int64(7), object(3)\nmemory usage: 57.2+ MB\n\n====== df:\n\n            id  Temparature  Humidity  Moisture Soil Type    Crop Type  \\\n0            0           37        70        36    Clayey    Sugarcane   \n1            1           27        69        65     Sandy      Millets   \n2            2           29        63        32     Sandy      Millets   \n3            3           35        62        54     Sandy       Barley   \n4            4           35        58        43       Red        Paddy   \n...        ...          ...       ...       ...       ...          ...   \n749995  749995           25        69        30    Clayey        Maize   \n749996  749996           37        64        58     Loamy    Sugarcane   \n749997  749997           35        68        59     Sandy  Ground Nuts   \n749998  749998           31        68        29       Red       Cotton   \n749999  749999           33        55        29     Loamy       Cotton   \n\n        Nitrogen  Potassium  Phosphorous Fertilizer Name  \n0             36          4            5           28-28  \n1             30          6           18           28-28  \n2             24         12           16        17-17-17  \n3             39         12            4        10-26-26  \n4             37          2           16             DAP  \n...          ...        ...          ...             ...  \n749995         8         16            6           28-28  \n749996        38          8           20        17-17-17  \n749997         6         11           29        10-26-26  \n749998         9         11           12           20-20  \n749999         4         10            9            Urea  \n\n[750000 rows x 10 columns]\n\n====== describe:\n\n                   id    Temparature       Humidity       Moisture Soil Type  \\\ncount   750000.000000  750000.000000  750000.000000  750000.000000    750000   \nunique            NaN            NaN            NaN            NaN         5   \ntop               NaN            NaN            NaN            NaN     Sandy   \nfreq              NaN            NaN            NaN            NaN    156710   \nmean    374999.500000      31.503565      61.038912      45.184147       NaN   \nstd     216506.495284       4.025574       6.647695      11.794594       NaN   \nmin          0.000000      25.000000      50.000000      25.000000       NaN   \n25%     187499.750000      28.000000      55.000000      35.000000       NaN   \n50%     374999.500000      32.000000      61.000000      45.000000       NaN   \n75%     562499.250000      35.000000      67.000000      55.000000       NaN   \nmax     749999.000000      38.000000      72.000000      65.000000       NaN   \n\n       Crop Type       Nitrogen      Potassium    Phosphorous Fertilizer Name  \ncount     750000  750000.000000  750000.000000  750000.000000          750000  \nunique        11            NaN            NaN            NaN               7  \ntop        Paddy            NaN            NaN            NaN        14-35-14  \nfreq       85754            NaN            NaN            NaN          114436  \nmean         NaN      23.093808       9.478296      21.073227             NaN  \nstd          NaN      11.216125       5.765622      12.346831             NaN  \nmin          NaN       4.000000       0.000000       0.000000             NaN  \n25%          NaN      13.000000       4.000000      10.000000             NaN  \n50%          NaN      23.000000       9.000000      21.000000             NaN  \n75%          NaN      33.000000      14.000000      32.000000             NaN  \nmax          NaN      42.000000      19.000000      42.000000             NaN  \n\n======info: \n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 750000 entries, 0 to 749999\nData columns (total 10 columns):\n #   Column           Non-Null Count   Dtype \n---  ------           --------------   ----- \n 0   id               750000 non-null  int64 \n 1   Temparature      750000 non-null  int64 \n 2   Humidity         750000 non-null  int64 \n 3   Moisture         750000 non-null  int64 \n 4   Soil Type        750000 non-null  object\n 5   Crop Type        750000 non-null  object\n 6   Nitrogen         750000 non-null  int64 \n 7   Potassium        750000 non-null  int64 \n 8   Phosphorous      750000 non-null  int64 \n 9   Fertilizer Name  750000 non-null  object\ndtypes: int64(7), object(3)\nmemory usage: 57.2+ MB\nNone\n\n====== null_count: \n\nid                 0\nTemparature        0\nHumidity           0\nMoisture           0\nSoil Type          0\nCrop Type          0\nNitrogen           0\nPotassium          0\nPhosphorous        0\nFertilizer Name    0\ndtype: int64\n\n====== unique_count: \n\nid                 750000\nTemparature            14\nHumidity               23\nMoisture               41\nSoil Type               5\nCrop Type              11\nNitrogen               39\nPotassium              20\nPhosphorous            43\nFertilizer Name         7\ndtype: int64\n\n====== unique_ratio: \n\nid                 1.000000\nTemparature        0.000019\nHumidity           0.000031\nMoisture           0.000055\nSoil Type          0.000007\nCrop Type          0.000015\nNitrogen           0.000052\nPotassium          0.000027\nPhosphorous        0.000057\nFertilizer Name    0.000009\ndtype: float64\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"name":"stdout","text":"Warning: Column 'Fertilizer Name' not found in train_encoded. Skipping...\nWarning: Column 'Fertilizer Name' not found in test_encoded. Skipping...\nTrain label column 'Fertilizer Name' is encoded with LabelEncoder.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"train_label_df.values.ravel()","metadata":{"execution":{"iopub.status.busy":"2025-06-26T22:45:20.158495Z","iopub.execute_input":"2025-06-26T22:45:20.158677Z","iopub.status.idle":"2025-06-26T22:45:20.163910Z","shell.execute_reply.started":"2025-06-26T22:45:20.158663Z","shell.execute_reply":"2025-06-26T22:45:20.162991Z"},"papermill":{"duration":0.012737,"end_time":"2025-06-24T14:56:15.967489","exception":false,"start_time":"2025-06-24T14:56:15.954752","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"array(['28-28', '28-28', '17-17-17', ..., '10-26-26', '20-20', 'Urea'],\n      dtype=object)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"print(f'train_encoded.info():\\n{train_encoded.info()}')\nprint(f'{train_encoded}')\nprint(f'test_encoded.info():{test_encoded.info()}')\nprint(f'{test_encoded}')\nprint(f'train_label_df.info():\\n{train_label_df.info()}')\nprint(f'{train_label_df}')","metadata":{"execution":{"iopub.status.busy":"2025-06-26T22:45:20.164675Z","iopub.execute_input":"2025-06-26T22:45:20.164945Z","iopub.status.idle":"2025-06-26T22:45:20.240347Z","shell.execute_reply.started":"2025-06-26T22:45:20.164929Z","shell.execute_reply":"2025-06-26T22:45:20.239682Z"},"papermill":{"duration":0.135648,"end_time":"2025-06-24T14:56:16.107208","exception":false,"start_time":"2025-06-24T14:56:15.971560","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 750000 entries, 0 to 749999\nData columns (total 8 columns):\n #   Column       Non-Null Count   Dtype   \n---  ------       --------------   -----   \n 0   Crop Type    750000 non-null  category\n 1   Humidity     750000 non-null  category\n 2   Moisture     750000 non-null  category\n 3   Nitrogen     750000 non-null  category\n 4   Phosphorous  750000 non-null  category\n 5   Potassium    750000 non-null  category\n 6   Soil Type    750000 non-null  category\n 7   Temparature  750000 non-null  category\ndtypes: category(8)\nmemory usage: 5.7 MB\ntrain_encoded.info():\nNone\n       Crop Type Humidity Moisture Nitrogen Phosphorous Potassium Soil Type  \\\n0              8       70       36       36           5         4         1   \n1              4       69       65       30          18         6         4   \n2              4       63       32       24          16        12         4   \n3              0       62       54       39           4        12         4   \n4              6       58       43       37          16         2         3   \n...          ...      ...      ...      ...         ...       ...       ...   \n749995         3       69       30        8           6        16         1   \n749996         8       64       58       38          20         8         2   \n749997         2       68       59        6          29        11         4   \n749998         1       68       29        9          12        11         3   \n749999         1       55       29        4           9        10         2   \n\n       Temparature  \n0               37  \n1               27  \n2               29  \n3               35  \n4               35  \n...            ...  \n749995          25  \n749996          37  \n749997          35  \n749998          31  \n749999          33  \n\n[750000 rows x 8 columns]\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 250000 entries, 0 to 249999\nData columns (total 8 columns):\n #   Column       Non-Null Count   Dtype   \n---  ------       --------------   -----   \n 0   Crop Type    250000 non-null  category\n 1   Humidity     250000 non-null  category\n 2   Moisture     250000 non-null  category\n 3   Nitrogen     250000 non-null  category\n 4   Phosphorous  250000 non-null  category\n 5   Potassium    250000 non-null  category\n 6   Soil Type    250000 non-null  category\n 7   Temparature  250000 non-null  category\ndtypes: category(8)\nmemory usage: 1.9 MB\ntest_encoded.info():None\n       Crop Type Humidity Moisture Nitrogen Phosphorous Potassium Soil Type  \\\n0             10       70       52       34          24        11         4   \n1              8       62       45       30          15        14         3   \n2              2       72       28       14           4        15         1   \n3              2       53       57       18          36        17         0   \n4              7       55       32       13          14        19         3   \n...          ...      ...      ...      ...         ...       ...       ...   \n249995         8       66       30       14          18         7         3   \n249996         7       62       55       28           7        14         3   \n249997         6       53       64       28          27        11         0   \n249998         6       67       26       33          10         0         1   \n249999         2       63       36       29          13         2         1   \n\n       Temparature  \n0               31  \n1               27  \n2               28  \n3               37  \n4               31  \n...            ...  \n249995          26  \n249996          33  \n249997          36  \n249998          36  \n249999          35  \n\n[250000 rows x 8 columns]\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 750000 entries, 0 to 749999\nData columns (total 1 columns):\n #   Column           Non-Null Count   Dtype \n---  ------           --------------   ----- \n 0   Fertilizer Name  750000 non-null  object\ndtypes: object(1)\nmemory usage: 5.7+ MB\ntrain_label_df.info():\nNone\n       Fertilizer Name\n0                28-28\n1                28-28\n2             17-17-17\n3             10-26-26\n4                  DAP\n...                ...\n749995           28-28\n749996        17-17-17\n749997        10-26-26\n749998           20-20\n749999            Urea\n\n[750000 rows x 1 columns]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training and Testing","metadata":{}},{"cell_type":"code","source":"######\n## Train models with cross_val_score()\n######\n\n## Set parameters\nrf_model_args = {\n    'n_estimators': 150,\n    'criterion': \"gini\",\n    'max_depth': 8,\n    'min_samples_split': 20,\n    'min_samples_leaf': 10,\n    'random_state': 42,\n    'max_features': \"sqrt\",\n    'n_jobs': -1,\n    'oob_score':True,\n    'max_samples': 0.85,\n    'verbose': 1,\n}\n\nrf_fit_cv_args = dict()\n\nrf_cv_args = {\n    'cv': 10,\n    'scoring': [\"neg_log_loss\", 'accuracy'],\n    'n_jobs': -1,\n    'verbose': 1,\n    'fit_params': rf_fit_cv_args,\n    'return_train_score': True,\n}\n\nx_rf = train_encoded\ny_rf = train_label_df.values.ravel()\n\n## Training and validation\nrf = RandomForestClassifier(**rf_model_args)\nrf_cv_scores = cross_validate(rf, x_rf, y_rf, **rf_cv_args)\nrf_cv_avg_scores = dict()\nfor k, v in rf_cv_scores.items():\n    mean_val = np.mean(v)\n    rf_cv_avg_scores[k] = mean_val\nprint(f\"\\nMean CV Score:\\n{rf_cv_avg_scores}\")\nprint(f\"\\nAll Fold Scores:\\n{rf_cv_scores}\")\n\nrf.fit(x_rf, y_rf) # Train on the whole training set as the final model.\njoblib.dump(rf, f'/kaggle/working/RandomForest_{timestamp}.joblib')\n\n## Predict on training data\ntrain_preds = rf.predict(x_rf)\n\n## Model analytics\nimportances = dict(zip(rf.feature_names_in_, rf.feature_importances_))\nsorted_importances = dict(sorted(\n    zip(rf.feature_names_in_, rf.feature_importances_),\n    key=lambda x: x[1],\n    reverse=True\n))\n","metadata":{"papermill":{"duration":1237.695581,"end_time":"2025-06-24T15:16:53.807528","exception":false,"start_time":"2025-06-24T14:56:16.111947","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T22:45:20.241178Z","iopub.execute_input":"2025-06-26T22:45:20.241457Z","iopub.status.idle":"2025-06-26T22:54:36.850989Z","shell.execute_reply.started":"2025-06-26T22:45:20.241434Z","shell.execute_reply":"2025-06-26T22:54:36.850276Z"}},"outputs":[{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   38.1s\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   41.0s\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   41.4s\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   42.0s\n[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.2min finished\n[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.3min finished\n[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.3min finished\n[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.3min finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.4s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.5s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.3s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.4s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.2s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.9s\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.0s\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.1s\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.7s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   15.6s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   17.1s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   17.1s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   16.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.5s\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.0s\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.4s\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.7s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   15.5s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   17.1s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   17.1s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   17.1s finished\n[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   32.3s\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   40.4s\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   40.5s\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   44.1s\n[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.1min finished\n[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.2min finished\n[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.2min finished\n[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.3min finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.4s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.3s\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.5s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.4s finished\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.2s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.6s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.9s finished\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.8s\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.7s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   12.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.6s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   15.1s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   15.8s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   12.6s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.4s\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.4s\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   10.2s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.5s\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.6s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   13.1s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   14.5s finished\n[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   13.0s finished\n[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.0s\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.5s\n[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   57.6s finished\n[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   55.7s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.6s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.6s finished\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.6s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.6s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.3s\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.7s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    8.7s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    8.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.6s\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.6s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    9.0s finished\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    8.8s finished\n[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  8.5min finished\n","output_type":"stream"},{"name":"stdout","text":"\nMean CV Score:\n{'fit_time': 140.4476202249527, 'score_time': 3.440329384803772, 'test_neg_log_loss': -1.9373605065290511, 'train_neg_log_loss': -1.933298287942608, 'test_accuracy': 0.170136, 'train_accuracy': 0.18679807407407406}\n\nAll Fold Scores:\n{'fit_time': array([157.19244123, 158.74196315, 160.13900232, 158.25234842,\n       153.01990819, 159.95883226, 155.46645617, 155.9661057 ,\n        75.67124772,  70.06789708]), 'score_time': array([3.28185821, 3.61354637, 3.57237744, 3.8195858 , 2.74893308,\n       4.90759063, 4.60085058, 4.09883118, 1.90382385, 1.85589671]), 'test_neg_log_loss': array([-1.93728084, -1.93758748, -1.93716961, -1.93732193, -1.93742376,\n       -1.93726957, -1.93736338, -1.9372968 , -1.93728867, -1.93760304]), 'train_neg_log_loss': array([-1.93325869, -1.93336416, -1.93318005, -1.93332031, -1.93329667,\n       -1.93339119, -1.93324778, -1.93325085, -1.93338112, -1.93329206]), 'test_accuracy': array([0.17054667, 0.17202667, 0.17064   , 0.17008   , 0.16953333,\n       0.16996   , 0.17162667, 0.16825333, 0.1694    , 0.16929333]), 'train_accuracy': array([0.18756889, 0.1864963 , 0.18827407, 0.18680741, 0.18733185,\n       0.18612   , 0.18700593, 0.18620741, 0.18553037, 0.18663852])}\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.6s\n[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   29.7s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.5s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    4.9s finished\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### Load and use pretrained LightGBM","metadata":{}},{"cell_type":"code","source":"# rf = joblib.load('RandomForest_20240624T170312.joblib')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T22:54:36.853091Z","iopub.execute_input":"2025-06-26T22:54:36.853525Z","iopub.status.idle":"2025-06-26T22:54:36.856528Z","shell.execute_reply.started":"2025-06-26T22:54:36.853506Z","shell.execute_reply":"2025-06-26T22:54:36.855843Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dict(sorted(\n    zip(rf.feature_names_in_, rf.feature_importances_),\n    key=lambda x: x[1],\n    reverse=True\n))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T22:54:36.857207Z","iopub.execute_input":"2025-06-26T22:54:36.857475Z","iopub.status.idle":"2025-06-26T22:54:36.898182Z","shell.execute_reply.started":"2025-06-26T22:54:36.857454Z","shell.execute_reply":"2025-06-26T22:54:36.897328Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'Crop Type': 0.21406853129943484,\n 'Moisture': 0.15385746711740494,\n 'Phosphorous': 0.1339453088750805,\n 'Nitrogen': 0.11841742561659152,\n 'Potassium': 0.11514333864576094,\n 'Soil Type': 0.09469581073801026,\n 'Humidity': 0.09260922365239543,\n 'Temparature': 0.07726289405532161}"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# ######\n# ## Train models with KFold()\n# ######\n\n# kf = KFold(n_splits=10, shuffle=True, random_state=42)\n# rf = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n\n# fold = 1\n# for train_index, val_index in kf.split(train_encoded):\n#     X_train, X_val = train_encoded.iloc[train_index], train_encoded.iloc[val_index]\n#     y_train, y_val = train_label_df.values.ravel()[train_index], train_label_df.values.ravel()[val_index]\n    \n#     rf.fit(X_train, y_train)\n#     preds = rf.predict(X_val)\n#     acc = accuracy_score(y_val, preds)\n    \n#     print(f\"Fold {fold} Accuracy: {acc:.4f}\")\n#     fold += 1","metadata":{"papermill":{"duration":0.011294,"end_time":"2025-06-24T15:16:53.823314","exception":false,"start_time":"2025-06-24T15:16:53.812020","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T22:54:36.898984Z","iopub.execute_input":"2025-06-26T22:54:36.899239Z","iopub.status.idle":"2025-06-26T22:54:36.903158Z","shell.execute_reply.started":"2025-06-26T22:54:36.899218Z","shell.execute_reply":"2025-06-26T22:54:36.902334Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"markdown","source":"### Single Label Prediction","metadata":{}},{"cell_type":"code","source":"# test_predict = rf.predict(test_encoded)\n# print(test_predict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T22:54:36.903883Z","iopub.execute_input":"2025-06-26T22:54:36.904574Z","iopub.status.idle":"2025-06-26T22:54:36.936089Z","shell.execute_reply.started":"2025-06-26T22:54:36.904558Z","shell.execute_reply":"2025-06-26T22:54:36.935330Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### MAP@k Prediction","metadata":{}},{"cell_type":"code","source":"# probs = rf.predict_proba(test_encoded)\n\n# top_predict = np.argsort(probs, axis=1)[:, -output_pred_num:][:, ::-1]\n# submission = pd.DataFrame({\n#     'id': test_df_src['id'].values,\n# })\n# submission[\"Fertilizer Name\"] = [\n#     \" \".join(rf.classes_[row]) for row in top_predict\n# ]\n\n# submission.to_csv('submission.csv', index=False)\n# print(submission)\n","metadata":{"papermill":{"duration":10.569788,"end_time":"2025-06-24T15:17:04.397612","exception":false,"start_time":"2025-06-24T15:16:53.827824","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T22:54:36.937025Z","iopub.execute_input":"2025-06-26T22:54:36.937317Z","iopub.status.idle":"2025-06-26T22:54:36.992569Z","shell.execute_reply.started":"2025-06-26T22:54:36.937293Z","shell.execute_reply":"2025-06-26T22:54:36.991882Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"### Meta-learner Prediction","metadata":{}},{"cell_type":"markdown","source":"#### Meta-learning feature creation","metadata":{}},{"cell_type":"code","source":"train_probs = rf.predict_proba(train_encoded)\ntest_probs = rf.predict_proba(test_encoded)\n\ntrain_meta_features = pd.DataFrame(\n    data=train_probs,\n    columns=rf.classes_\n)\n\ntest_meta_features = pd.DataFrame(\n    data=test_probs,\n    columns=rf.classes_\n)\n\ntop_num = None  # Natural numbers or None to take all.\ntop_features = list(sorted_importances.keys()) if top_num is None else list(sorted_importances.keys())[:top_num]\n\n\nextended_train_meta_features = pd.merge(train_encoded[top_features], train_meta_features, left_index=True, right_index=True, how=\"left\")\nextended_test_meta_features = pd.merge(test_encoded[top_features], test_meta_features, left_index=True, right_index=True, how=\"left\")\n\n# extended_train_meta_features = train_encoded\n# extended_test_meta_features = test_encoded\n\nextended_train_meta_features = sort_columns(extended_train_meta_features)\nextended_test_meta_features = sort_columns(extended_test_meta_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T22:54:36.993333Z","iopub.execute_input":"2025-06-26T22:54:36.993546Z","iopub.status.idle":"2025-06-26T22:54:43.749914Z","shell.execute_reply.started":"2025-06-26T22:54:36.993531Z","shell.execute_reply":"2025-06-26T22:54:43.749108Z"}},"outputs":[{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.5s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    5.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    1.5s finished\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"extended_train_meta_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T22:54:43.750615Z","iopub.execute_input":"2025-06-26T22:54:43.750829Z","iopub.status.idle":"2025-06-26T22:54:43.767310Z","shell.execute_reply.started":"2025-06-26T22:54:43.750805Z","shell.execute_reply":"2025-06-26T22:54:43.766738Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"        10-26-26  14-35-14  17-17-17     20-20     28-28 Crop Type       DAP  \\\n0       0.159948  0.158043  0.155687  0.154859  0.148813         8  0.114922   \n1       0.137220  0.142944  0.139023  0.148303  0.161374         4  0.137869   \n2       0.145215  0.153883  0.148962  0.138722  0.147859         4  0.130642   \n3       0.144518  0.150372  0.146424  0.141160  0.146278         0  0.133150   \n4       0.144485  0.151341  0.144961  0.135617  0.150718         6  0.138343   \n...          ...       ...       ...       ...       ...       ...       ...   \n749995  0.156966  0.152761  0.149556  0.147131  0.149932         3  0.122287   \n749996  0.157519  0.159591  0.156122  0.155435  0.152308         8  0.113480   \n749997  0.140197  0.138979  0.141141  0.146626  0.173830         2  0.123507   \n749998  0.141648  0.147496  0.148567  0.143930  0.151930         1  0.128996   \n749999  0.153833  0.156846  0.140612  0.143086  0.147420         1  0.128359   \n\n       Humidity Moisture Nitrogen Phosphorous Potassium Soil Type Temparature  \\\n0            70       36       36           5         4         1          37   \n1            69       65       30          18         6         4          27   \n2            63       32       24          16        12         4          29   \n3            62       54       39           4        12         4          35   \n4            58       43       37          16         2         3          35   \n...         ...      ...      ...         ...       ...       ...         ...   \n749995       69       30        8           6        16         1          25   \n749996       64       58       38          20         8         2          37   \n749997       68       59        6          29        11         4          35   \n749998       68       29        9          12        11         3          31   \n749999       55       29        4           9        10         2          33   \n\n            Urea  \n0       0.107728  \n1       0.133266  \n2       0.134716  \n3       0.138100  \n4       0.134535  \n...          ...  \n749995  0.121367  \n749996  0.105545  \n749997  0.135720  \n749998  0.137432  \n749999  0.129844  \n\n[750000 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>10-26-26</th>\n      <th>14-35-14</th>\n      <th>17-17-17</th>\n      <th>20-20</th>\n      <th>28-28</th>\n      <th>Crop Type</th>\n      <th>DAP</th>\n      <th>Humidity</th>\n      <th>Moisture</th>\n      <th>Nitrogen</th>\n      <th>Phosphorous</th>\n      <th>Potassium</th>\n      <th>Soil Type</th>\n      <th>Temparature</th>\n      <th>Urea</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.159948</td>\n      <td>0.158043</td>\n      <td>0.155687</td>\n      <td>0.154859</td>\n      <td>0.148813</td>\n      <td>8</td>\n      <td>0.114922</td>\n      <td>70</td>\n      <td>36</td>\n      <td>36</td>\n      <td>5</td>\n      <td>4</td>\n      <td>1</td>\n      <td>37</td>\n      <td>0.107728</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.137220</td>\n      <td>0.142944</td>\n      <td>0.139023</td>\n      <td>0.148303</td>\n      <td>0.161374</td>\n      <td>4</td>\n      <td>0.137869</td>\n      <td>69</td>\n      <td>65</td>\n      <td>30</td>\n      <td>18</td>\n      <td>6</td>\n      <td>4</td>\n      <td>27</td>\n      <td>0.133266</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.145215</td>\n      <td>0.153883</td>\n      <td>0.148962</td>\n      <td>0.138722</td>\n      <td>0.147859</td>\n      <td>4</td>\n      <td>0.130642</td>\n      <td>63</td>\n      <td>32</td>\n      <td>24</td>\n      <td>16</td>\n      <td>12</td>\n      <td>4</td>\n      <td>29</td>\n      <td>0.134716</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.144518</td>\n      <td>0.150372</td>\n      <td>0.146424</td>\n      <td>0.141160</td>\n      <td>0.146278</td>\n      <td>0</td>\n      <td>0.133150</td>\n      <td>62</td>\n      <td>54</td>\n      <td>39</td>\n      <td>4</td>\n      <td>12</td>\n      <td>4</td>\n      <td>35</td>\n      <td>0.138100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.144485</td>\n      <td>0.151341</td>\n      <td>0.144961</td>\n      <td>0.135617</td>\n      <td>0.150718</td>\n      <td>6</td>\n      <td>0.138343</td>\n      <td>58</td>\n      <td>43</td>\n      <td>37</td>\n      <td>16</td>\n      <td>2</td>\n      <td>3</td>\n      <td>35</td>\n      <td>0.134535</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>749995</th>\n      <td>0.156966</td>\n      <td>0.152761</td>\n      <td>0.149556</td>\n      <td>0.147131</td>\n      <td>0.149932</td>\n      <td>3</td>\n      <td>0.122287</td>\n      <td>69</td>\n      <td>30</td>\n      <td>8</td>\n      <td>6</td>\n      <td>16</td>\n      <td>1</td>\n      <td>25</td>\n      <td>0.121367</td>\n    </tr>\n    <tr>\n      <th>749996</th>\n      <td>0.157519</td>\n      <td>0.159591</td>\n      <td>0.156122</td>\n      <td>0.155435</td>\n      <td>0.152308</td>\n      <td>8</td>\n      <td>0.113480</td>\n      <td>64</td>\n      <td>58</td>\n      <td>38</td>\n      <td>20</td>\n      <td>8</td>\n      <td>2</td>\n      <td>37</td>\n      <td>0.105545</td>\n    </tr>\n    <tr>\n      <th>749997</th>\n      <td>0.140197</td>\n      <td>0.138979</td>\n      <td>0.141141</td>\n      <td>0.146626</td>\n      <td>0.173830</td>\n      <td>2</td>\n      <td>0.123507</td>\n      <td>68</td>\n      <td>59</td>\n      <td>6</td>\n      <td>29</td>\n      <td>11</td>\n      <td>4</td>\n      <td>35</td>\n      <td>0.135720</td>\n    </tr>\n    <tr>\n      <th>749998</th>\n      <td>0.141648</td>\n      <td>0.147496</td>\n      <td>0.148567</td>\n      <td>0.143930</td>\n      <td>0.151930</td>\n      <td>1</td>\n      <td>0.128996</td>\n      <td>68</td>\n      <td>29</td>\n      <td>9</td>\n      <td>12</td>\n      <td>11</td>\n      <td>3</td>\n      <td>31</td>\n      <td>0.137432</td>\n    </tr>\n    <tr>\n      <th>749999</th>\n      <td>0.153833</td>\n      <td>0.156846</td>\n      <td>0.140612</td>\n      <td>0.143086</td>\n      <td>0.147420</td>\n      <td>1</td>\n      <td>0.128359</td>\n      <td>55</td>\n      <td>29</td>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>2</td>\n      <td>33</td>\n      <td>0.129844</td>\n    </tr>\n  </tbody>\n</table>\n<p>750000 rows × 15 columns</p>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"#### Define inputs","metadata":{}},{"cell_type":"code","source":"x_meta = extended_train_meta_features\ny_meta = train_label_df.values.ravel()\nprint(y_meta)\n\nlgbm_model_args = {\n    'objective': 'multiclass',\n    'num_class': 7,\n    'boosting_type': 'gbdt',\n    'n_estimators': 1000,\n    'early_stopping_round': 100,  # No effect, only for compatibility. Call early_stopping in fit directly.\n    'learning_rate': 0.03,\n    \"num_leaves\": 31,\n    'max_depth': 8,\n    'random_state': 42,\n    'reg_alpha': 1.0, \n    'reg_lambda': 1.0,\n    'device_type': 'gpu',\n    'verbosity': -1,\n}\n\nlgbm_fit_cv_args = {\n    # 'eval_set': [(x_valid, y_valid)],\n    # 'callbacks': [lgb.early_stopping(stopping_rounds=50)],  # Early stopping not supported in sklearn cross_validate().\n    'eval_metric': ['multi_logloss', 'multi_error'],  \n}\n\nlgbm_fit_custom_args = {\n    'eval_set': None,\n    'eval_metric': ['multi_logloss', 'multi_error'],\n    'callbacks':[\n        lgb.early_stopping(stopping_rounds=lgbm_model_args['early_stopping_round']),\n        lgb.log_evaluation(period=40)\n    ],\n}\n\nlgbm_cv_args = {\n    'cv': 10,\n    'n_jobs': -1,\n    'verbose': 2,\n    'fit_params': lgbm_fit_cv_args\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T22:54:43.768035Z","iopub.execute_input":"2025-06-26T22:54:43.768285Z","iopub.status.idle":"2025-06-26T22:54:43.788543Z","shell.execute_reply.started":"2025-06-26T22:54:43.768263Z","shell.execute_reply":"2025-06-26T22:54:43.788013Z"}},"outputs":[{"name":"stdout","text":"['28-28' '28-28' '17-17-17' ... '10-26-26' '20-20' 'Urea']\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"#### Model with cross_validate","metadata":{}},{"cell_type":"code","source":"# lgbm = lgb.LGBMClassifier(**lgbm_model_args)\n# lgbm_cv_scores = cross_validate(lgbm, x_meta, y_meta, **lgbm_cv_args)\n# lgbm_cv_avg_scores = dict()\n# for k, v in lgbm_cv_scores.items():\n#     mean_val = np.mean(v)\n#     lgbm_cv_avg_scores[k] = mean_val\n# print(f\"\\nMean CV Score:\\n{lgbm_cv_avg_scores}\")\n# print(f\"\\nAll Fold Scores:\\n{lgbm_cv_scores}\")\n\n# lgbm.fit(x_meta, y_meta, **lgbm_fit_cv_args)\n# lgbm.booster_.save_model('/kaggle/working/LightGBM_{}.txt'.format(timestamp))\n\n# # Predict on training data\n# train_preds = lgbm.predict(x_meta)\n\n# # # Method 1: Using .score()\n# # train_accuracy = lgbm.score(x_meta, y_meta)\n\n# # Method 2: Using accuracy_score\n# train_accuracy = accuracy_score(y_meta, train_preds)\n# print(f\"Training Accuracy: {train_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T22:54:43.789230Z","iopub.execute_input":"2025-06-26T22:54:43.789500Z","iopub.status.idle":"2025-06-26T22:54:43.801072Z","shell.execute_reply.started":"2025-06-26T22:54:43.789480Z","shell.execute_reply":"2025-06-26T22:54:43.800518Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"#### Model with custom flow\n\nkfold_num = lgbm_cv_args['cv']\nkf = StratifiedKFold(n_splits=kfold_num, shuffle=True, random_state=42)\ntest_pred_prob_all_folds = list()\nbest_iters = dict()\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(x_meta, y_meta)):\n    print(f'train_idx is {train_idx}, length is {len(train_idx)}')\n    print(f'val_idx is {val_idx}, length is {len(val_idx)}')\n    lgbm = lgb.LGBMClassifier(**lgbm_model_args)\n    x_train, x_val = x_meta.iloc[train_idx], x_meta.iloc[val_idx]\n    y_train, y_val = y_meta[train_idx], y_meta[val_idx]\n    lgbm_fit_custom_args['eval_set'] = [\n        (x_val, y_val),\n        (x_train, y_train)\n    ]\n    # lgbm_fit_custom_args['eval_set'] = [(x_val, y_val)]\n    lgbm.fit(x_train, y_train, **lgbm_fit_custom_args)\n    lgbm_fit_custom_args['eval_set'] = None\n    lgbm.booster_.save_model('/kaggle/working/LightGBM_fold{}_{}.txt'.format(fold, timestamp))\n    # Model evaluation\n    best_iter = lgbm.best_iteration_\n    best_iters[fold] = best_iter\n    num_iteration = best_iter + 0\n    labels = lgbm._classes\n    \n    eval_result = lgbm.evals_result_\n    final_logloss = eval_result['valid_0']['multi_logloss'][best_iter - 1]\n    final_error = eval_result['valid_0']['multi_error'][best_iter - 1]\n    print(f\"[Fold {fold}] Final log loss: {final_logloss:.5f}, Final error: {final_error:.5f}\")\n    \n    pred_prob_train = lgbm.predict_proba(x_train, num_iteration=num_iteration)\n    pred_prob_val = lgbm.predict_proba(x_val, num_iteration=num_iteration)\n    pred_train = lgbm.predict(x_train, num_iteration=num_iteration)\n    pred_val = lgbm.predict(x_val, num_iteration=num_iteration)\n    # print(\"LightGBM Train Accuracy:\", accuracy_score(y_train, pred_train))  \n    # print(\"LightGBM Validation Accuracy:\", accuracy_score(y_val, pred_val)) \n    \n    mapk_train = mapk(y_train, pred_prob_train, k=3, labels=labels)\n    mapk_val = mapk(y_val, pred_prob_val, k=3, labels=labels)\n    print(\"LightGBM Train MAP3:\", mapk_train)\n    print(\"LightGBM Validation MAP3:\", mapk_val)\n    \n    # Make prediction\n    test_pred_prob = lgbm.predict_proba(extended_test_meta_features, num_iteration=num_iteration)\n    test_pred_prob_all_folds.append(test_pred_prob)\n    print(f\"\\n[Fold {fold} is finished.]\\n\\n\\n\")\n    # break\n    \n# Shape: (n_folds, n_samples, n_classes)\nstacked_preds = np.stack(test_pred_prob_all_folds, axis=0)\n\n# Average across folds\nkfold_avg_probs = np.mean(stacked_preds, axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T22:54:43.801640Z","iopub.execute_input":"2025-06-26T22:54:43.801797Z","iopub.status.idle":"2025-06-27T00:56:45.735119Z","shell.execute_reply.started":"2025-06-26T22:54:43.801784Z","shell.execute_reply":"2025-06-27T00:56:45.734330Z"}},"outputs":[{"name":"stdout","text":"train_idx is [     0      3      4 ... 749997 749998 749999], length is 675000\nval_idx is [     1      2      8 ... 749958 749959 749991], length is 75000\n","output_type":"stream"},{"name":"stderr","text":"1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 100 rounds\n[40]\ttraining's multi_logloss: 1.90653\ttraining's multi_error: 0.780631\tvalid_0's multi_logloss: 1.91358\tvalid_0's multi_error: 0.794107\n[80]\ttraining's multi_logloss: 1.89192\ttraining's multi_error: 0.769145\tvalid_0's multi_logloss: 1.90599\tvalid_0's multi_error: 0.789067\n[120]\ttraining's multi_logloss: 1.8811\ttraining's multi_error: 0.759738\tvalid_0's multi_logloss: 1.90201\tvalid_0's multi_error: 0.78676\n[160]\ttraining's multi_logloss: 1.87182\ttraining's multi_error: 0.751676\tvalid_0's multi_logloss: 1.89917\tvalid_0's multi_error: 0.784587\n[200]\ttraining's multi_logloss: 1.86354\ttraining's multi_error: 0.744578\tvalid_0's multi_logloss: 1.89732\tvalid_0's multi_error: 0.78272\n[240]\ttraining's multi_logloss: 1.85595\ttraining's multi_error: 0.738039\tvalid_0's multi_logloss: 1.89593\tvalid_0's multi_error: 0.781987\n[280]\ttraining's multi_logloss: 1.84893\ttraining's multi_error: 0.732062\tvalid_0's multi_logloss: 1.89492\tvalid_0's multi_error: 0.7812\n[320]\ttraining's multi_logloss: 1.8423\ttraining's multi_error: 0.726259\tvalid_0's multi_logloss: 1.89405\tvalid_0's multi_error: 0.780387\n[360]\ttraining's multi_logloss: 1.83596\ttraining's multi_error: 0.720508\tvalid_0's multi_logloss: 1.89334\tvalid_0's multi_error: 0.78016\n[400]\ttraining's multi_logloss: 1.82982\ttraining's multi_error: 0.715154\tvalid_0's multi_logloss: 1.89279\tvalid_0's multi_error: 0.779853\n[440]\ttraining's multi_logloss: 1.82379\ttraining's multi_error: 0.709858\tvalid_0's multi_logloss: 1.89232\tvalid_0's multi_error: 0.77916\n[480]\ttraining's multi_logloss: 1.81796\ttraining's multi_error: 0.704844\tvalid_0's multi_logloss: 1.89186\tvalid_0's multi_error: 0.779427\n[520]\ttraining's multi_logloss: 1.81223\ttraining's multi_error: 0.699603\tvalid_0's multi_logloss: 1.89152\tvalid_0's multi_error: 0.778787\n[560]\ttraining's multi_logloss: 1.80668\ttraining's multi_error: 0.694721\tvalid_0's multi_logloss: 1.8912\tvalid_0's multi_error: 0.77872\n[600]\ttraining's multi_logloss: 1.80121\ttraining's multi_error: 0.690156\tvalid_0's multi_logloss: 1.89088\tvalid_0's multi_error: 0.7788\n[640]\ttraining's multi_logloss: 1.79588\ttraining's multi_error: 0.685292\tvalid_0's multi_logloss: 1.8906\tvalid_0's multi_error: 0.778293\n[680]\ttraining's multi_logloss: 1.79058\ttraining's multi_error: 0.680582\tvalid_0's multi_logloss: 1.89036\tvalid_0's multi_error: 0.77788\n[720]\ttraining's multi_logloss: 1.78541\ttraining's multi_error: 0.675991\tvalid_0's multi_logloss: 1.89016\tvalid_0's multi_error: 0.77748\n[760]\ttraining's multi_logloss: 1.7803\ttraining's multi_error: 0.671653\tvalid_0's multi_logloss: 1.88996\tvalid_0's multi_error: 0.777573\n[800]\ttraining's multi_logloss: 1.77529\ttraining's multi_error: 0.667218\tvalid_0's multi_logloss: 1.88976\tvalid_0's multi_error: 0.7776\n[840]\ttraining's multi_logloss: 1.77027\ttraining's multi_error: 0.6626\tvalid_0's multi_logloss: 1.88968\tvalid_0's multi_error: 0.777773\n[Fold 0] Final log loss: 1.89005, Final error: 0.77715\nLightGBM Train MAP3: 0.4763212345678412\nLightGBM Validation MAP3: 0.3607488888888395\n\n[Fold 0 is finished.]\n\n\n\ntrain_idx is [     0      1      2 ... 749996 749997 749999], length is 675000\nval_idx is [     5      6     30 ... 749993 749995 749998], length is 75000\nTraining until validation scores don't improve for 100 rounds\n[40]\ttraining's multi_logloss: 1.90652\ttraining's multi_error: 0.780347\tvalid_0's multi_logloss: 1.9134\tvalid_0's multi_error: 0.79444\n[80]\ttraining's multi_logloss: 1.8919\ttraining's multi_error: 0.768631\tvalid_0's multi_logloss: 1.90561\tvalid_0's multi_error: 0.789907\n[120]\ttraining's multi_logloss: 1.88106\ttraining's multi_error: 0.759216\tvalid_0's multi_logloss: 1.90147\tvalid_0's multi_error: 0.78796\n[160]\ttraining's multi_logloss: 1.87172\ttraining's multi_error: 0.751427\tvalid_0's multi_logloss: 1.89854\tvalid_0's multi_error: 0.78528\n[200]\ttraining's multi_logloss: 1.86345\ttraining's multi_error: 0.744007\tvalid_0's multi_logloss: 1.89655\tvalid_0's multi_error: 0.783827\n[240]\ttraining's multi_logloss: 1.8559\ttraining's multi_error: 0.737644\tvalid_0's multi_logloss: 1.89512\tvalid_0's multi_error: 0.782627\n[280]\ttraining's multi_logloss: 1.84886\ttraining's multi_error: 0.731633\tvalid_0's multi_logloss: 1.89412\tvalid_0's multi_error: 0.78132\n[320]\ttraining's multi_logloss: 1.84224\ttraining's multi_error: 0.725781\tvalid_0's multi_logloss: 1.89333\tvalid_0's multi_error: 0.780867\n[360]\ttraining's multi_logloss: 1.8359\ttraining's multi_error: 0.720213\tvalid_0's multi_logloss: 1.89272\tvalid_0's multi_error: 0.780507\n[400]\ttraining's multi_logloss: 1.82977\ttraining's multi_error: 0.714822\tvalid_0's multi_logloss: 1.89218\tvalid_0's multi_error: 0.779507\n[440]\ttraining's multi_logloss: 1.82382\ttraining's multi_error: 0.709539\tvalid_0's multi_logloss: 1.89173\tvalid_0's multi_error: 0.779427\n[480]\ttraining's multi_logloss: 1.81798\ttraining's multi_error: 0.704524\tvalid_0's multi_logloss: 1.89136\tvalid_0's multi_error: 0.779467\n[520]\ttraining's multi_logloss: 1.81227\ttraining's multi_error: 0.69967\tvalid_0's multi_logloss: 1.89095\tvalid_0's multi_error: 0.779187\n[560]\ttraining's multi_logloss: 1.80676\ttraining's multi_error: 0.695009\tvalid_0's multi_logloss: 1.89069\tvalid_0's multi_error: 0.779093\n[600]\ttraining's multi_logloss: 1.80133\ttraining's multi_error: 0.690043\tvalid_0's multi_logloss: 1.89045\tvalid_0's multi_error: 0.779187\n[640]\ttraining's multi_logloss: 1.79599\ttraining's multi_error: 0.685308\tvalid_0's multi_logloss: 1.89013\tvalid_0's multi_error: 0.778693\n[680]\ttraining's multi_logloss: 1.79074\ttraining's multi_error: 0.680756\tvalid_0's multi_logloss: 1.88995\tvalid_0's multi_error: 0.778747\n[720]\ttraining's multi_logloss: 1.78554\ttraining's multi_error: 0.67592\tvalid_0's multi_logloss: 1.88978\tvalid_0's multi_error: 0.778427\nEarly stopping, best iteration is:\n[634]\ttraining's multi_logloss: 1.79678\ttraining's multi_error: 0.686121\tvalid_0's multi_logloss: 1.89018\tvalid_0's multi_error: 0.77836\n[Fold 1] Final log loss: 1.89018, Final error: 0.77836\nLightGBM Train MAP3: 0.46330641975310904\nLightGBM Validation MAP3: 0.36109111111105907\n\n[Fold 1 is finished.]\n\n\n\ntrain_idx is [     0      1      2 ... 749997 749998 749999], length is 675000\nval_idx is [    22     24     26 ... 749967 749976 749985], length is 75000\nTraining until validation scores don't improve for 100 rounds\n[40]\ttraining's multi_logloss: 1.90657\ttraining's multi_error: 0.780388\tvalid_0's multi_logloss: 1.91335\tvalid_0's multi_error: 0.7928\n[80]\ttraining's multi_logloss: 1.89195\ttraining's multi_error: 0.769067\tvalid_0's multi_logloss: 1.90558\tvalid_0's multi_error: 0.788027\n[120]\ttraining's multi_logloss: 1.88125\ttraining's multi_error: 0.760098\tvalid_0's multi_logloss: 1.90153\tvalid_0's multi_error: 0.785227\n[160]\ttraining's multi_logloss: 1.87192\ttraining's multi_error: 0.752203\tvalid_0's multi_logloss: 1.89869\tvalid_0's multi_error: 0.784\n[200]\ttraining's multi_logloss: 1.86366\ttraining's multi_error: 0.745043\tvalid_0's multi_logloss: 1.89677\tvalid_0's multi_error: 0.782213\n[240]\ttraining's multi_logloss: 1.85608\ttraining's multi_error: 0.738613\tvalid_0's multi_logloss: 1.89541\tvalid_0's multi_error: 0.78136\n[280]\ttraining's multi_logloss: 1.849\ttraining's multi_error: 0.732717\tvalid_0's multi_logloss: 1.89435\tvalid_0's multi_error: 0.780747\n[320]\ttraining's multi_logloss: 1.8424\ttraining's multi_error: 0.726825\tvalid_0's multi_logloss: 1.89356\tvalid_0's multi_error: 0.78016\n[360]\ttraining's multi_logloss: 1.83606\ttraining's multi_error: 0.721387\tvalid_0's multi_logloss: 1.89287\tvalid_0's multi_error: 0.779387\n[400]\ttraining's multi_logloss: 1.82988\ttraining's multi_error: 0.71568\tvalid_0's multi_logloss: 1.89234\tvalid_0's multi_error: 0.779347\n[440]\ttraining's multi_logloss: 1.82395\ttraining's multi_error: 0.710729\tvalid_0's multi_logloss: 1.89194\tvalid_0's multi_error: 0.779253\n[480]\ttraining's multi_logloss: 1.8181\ttraining's multi_error: 0.705507\tvalid_0's multi_logloss: 1.89158\tvalid_0's multi_error: 0.77844\n[520]\ttraining's multi_logloss: 1.81243\ttraining's multi_error: 0.700588\tvalid_0's multi_logloss: 1.89121\tvalid_0's multi_error: 0.777973\n[560]\ttraining's multi_logloss: 1.80693\ttraining's multi_error: 0.695575\tvalid_0's multi_logloss: 1.89086\tvalid_0's multi_error: 0.777893\n[600]\ttraining's multi_logloss: 1.8015\ttraining's multi_error: 0.69087\tvalid_0's multi_logloss: 1.89054\tvalid_0's multi_error: 0.777653\n[640]\ttraining's multi_logloss: 1.7961\ttraining's multi_error: 0.68592\tvalid_0's multi_logloss: 1.89022\tvalid_0's multi_error: 0.777467\n[680]\ttraining's multi_logloss: 1.79082\ttraining's multi_error: 0.681313\tvalid_0's multi_logloss: 1.88992\tvalid_0's multi_error: 0.777307\n[720]\ttraining's multi_logloss: 1.7856\ttraining's multi_error: 0.676473\tvalid_0's multi_logloss: 1.88969\tvalid_0's multi_error: 0.77676\n[760]\ttraining's multi_logloss: 1.78042\ttraining's multi_error: 0.67213\tvalid_0's multi_logloss: 1.88947\tvalid_0's multi_error: 0.77668\n[800]\ttraining's multi_logloss: 1.77535\ttraining's multi_error: 0.667479\tvalid_0's multi_logloss: 1.8893\tvalid_0's multi_error: 0.77672\n[840]\ttraining's multi_logloss: 1.77037\ttraining's multi_error: 0.662933\tvalid_0's multi_logloss: 1.88917\tvalid_0's multi_error: 0.776787\n[880]\ttraining's multi_logloss: 1.76541\ttraining's multi_error: 0.658521\tvalid_0's multi_logloss: 1.88901\tvalid_0's multi_error: 0.776587\n[920]\ttraining's multi_logloss: 1.76059\ttraining's multi_error: 0.654076\tvalid_0's multi_logloss: 1.8889\tvalid_0's multi_error: 0.776613\n[960]\ttraining's multi_logloss: 1.7557\ttraining's multi_error: 0.649658\tvalid_0's multi_logloss: 1.88877\tvalid_0's multi_error: 0.77592\n[1000]\ttraining's multi_logloss: 1.75099\ttraining's multi_error: 0.64553\tvalid_0's multi_logloss: 1.88865\tvalid_0's multi_error: 0.775707\nDid not meet early stopping. Best iteration is:\n[998]\ttraining's multi_logloss: 1.75119\ttraining's multi_error: 0.64564\tvalid_0's multi_logloss: 1.88864\tvalid_0's multi_error: 0.77556\n[Fold 2] Final log loss: 1.88864, Final error: 0.77556\nLightGBM Train MAP3: 0.5065916049380428\nLightGBM Validation MAP3: 0.36276888888883807\n\n[Fold 2 is finished.]\n\n\n\ntrain_idx is [     0      1      2 ... 749996 749997 749998], length is 675000\nval_idx is [     4     17     33 ... 749977 749987 749999], length is 75000\nTraining until validation scores don't improve for 100 rounds\n[40]\ttraining's multi_logloss: 1.90665\ttraining's multi_error: 0.780292\tvalid_0's multi_logloss: 1.91284\tvalid_0's multi_error: 0.794533\n[80]\ttraining's multi_logloss: 1.89203\ttraining's multi_error: 0.768587\tvalid_0's multi_logloss: 1.90494\tvalid_0's multi_error: 0.790267\n[120]\ttraining's multi_logloss: 1.88122\ttraining's multi_error: 0.75929\tvalid_0's multi_logloss: 1.90094\tvalid_0's multi_error: 0.787667\n[160]\ttraining's multi_logloss: 1.87189\ttraining's multi_error: 0.75143\tvalid_0's multi_logloss: 1.89826\tvalid_0's multi_error: 0.78608\n[200]\ttraining's multi_logloss: 1.8636\ttraining's multi_error: 0.74453\tvalid_0's multi_logloss: 1.89632\tvalid_0's multi_error: 0.784493\n[240]\ttraining's multi_logloss: 1.85602\ttraining's multi_error: 0.737815\tvalid_0's multi_logloss: 1.8949\tvalid_0's multi_error: 0.783253\n[280]\ttraining's multi_logloss: 1.849\ttraining's multi_error: 0.731633\tvalid_0's multi_logloss: 1.89375\tvalid_0's multi_error: 0.782667\n[320]\ttraining's multi_logloss: 1.84236\ttraining's multi_error: 0.726216\tvalid_0's multi_logloss: 1.89291\tvalid_0's multi_error: 0.782533\n[360]\ttraining's multi_logloss: 1.83598\ttraining's multi_error: 0.720501\tvalid_0's multi_logloss: 1.89224\tvalid_0's multi_error: 0.781693\n[400]\ttraining's multi_logloss: 1.82979\ttraining's multi_error: 0.715145\tvalid_0's multi_logloss: 1.89168\tvalid_0's multi_error: 0.781467\n[440]\ttraining's multi_logloss: 1.82378\ttraining's multi_error: 0.710126\tvalid_0's multi_logloss: 1.89115\tvalid_0's multi_error: 0.780947\n[480]\ttraining's multi_logloss: 1.81796\ttraining's multi_error: 0.705095\tvalid_0's multi_logloss: 1.89075\tvalid_0's multi_error: 0.78064\n[520]\ttraining's multi_logloss: 1.81229\ttraining's multi_error: 0.699985\tvalid_0's multi_logloss: 1.89042\tvalid_0's multi_error: 0.780387\n[560]\ttraining's multi_logloss: 1.80674\ttraining's multi_error: 0.695341\tvalid_0's multi_logloss: 1.89006\tvalid_0's multi_error: 0.78004\n[600]\ttraining's multi_logloss: 1.80126\ttraining's multi_error: 0.69055\tvalid_0's multi_logloss: 1.88975\tvalid_0's multi_error: 0.77976\n[640]\ttraining's multi_logloss: 1.7959\ttraining's multi_error: 0.685742\tvalid_0's multi_logloss: 1.88947\tvalid_0's multi_error: 0.779107\n[680]\ttraining's multi_logloss: 1.79063\ttraining's multi_error: 0.681188\tvalid_0's multi_logloss: 1.88931\tvalid_0's multi_error: 0.779173\n[720]\ttraining's multi_logloss: 1.78544\ttraining's multi_error: 0.676292\tvalid_0's multi_logloss: 1.88907\tvalid_0's multi_error: 0.779013\n[760]\ttraining's multi_logloss: 1.78033\ttraining's multi_error: 0.671954\tvalid_0's multi_logloss: 1.88887\tvalid_0's multi_error: 0.778693\n[800]\ttraining's multi_logloss: 1.77529\ttraining's multi_error: 0.667409\tvalid_0's multi_logloss: 1.88872\tvalid_0's multi_error: 0.779133\n[840]\ttraining's multi_logloss: 1.77032\ttraining's multi_error: 0.662699\tvalid_0's multi_logloss: 1.88863\tvalid_0's multi_error: 0.778173\n[880]\ttraining's multi_logloss: 1.76539\ttraining's multi_error: 0.658369\tvalid_0's multi_logloss: 1.88854\tvalid_0's multi_error: 0.778053\n[920]\ttraining's multi_logloss: 1.76049\ttraining's multi_error: 0.65391\tvalid_0's multi_logloss: 1.88844\tvalid_0's multi_error: 0.77752\n[960]\ttraining's multi_logloss: 1.7557\ttraining's multi_error: 0.649473\tvalid_0's multi_logloss: 1.88837\tvalid_0's multi_error: 0.77772\n[1000]\ttraining's multi_logloss: 1.7509\ttraining's multi_error: 0.645068\tvalid_0's multi_logloss: 1.8882\tvalid_0's multi_error: 0.777027\nDid not meet early stopping. Best iteration is:\n[1000]\ttraining's multi_logloss: 1.7509\ttraining's multi_error: 0.645068\tvalid_0's multi_logloss: 1.8882\tvalid_0's multi_error: 0.777027\n[Fold 3] Final log loss: 1.88820, Final error: 0.77703\nLightGBM Train MAP3: 0.5064232098763155\nLightGBM Validation MAP3: 0.3621511111110609\n\n[Fold 3 is finished.]\n\n\n\ntrain_idx is [     0      1      2 ... 749997 749998 749999], length is 675000\nval_idx is [     3     63     66 ... 749961 749970 749971], length is 75000\nTraining until validation scores don't improve for 100 rounds\n[40]\ttraining's multi_logloss: 1.90654\ttraining's multi_error: 0.780364\tvalid_0's multi_logloss: 1.91362\tvalid_0's multi_error: 0.794547\n[80]\ttraining's multi_logloss: 1.89193\ttraining's multi_error: 0.768954\tvalid_0's multi_logloss: 1.90574\tvalid_0's multi_error: 0.790693\n[120]\ttraining's multi_logloss: 1.88118\ttraining's multi_error: 0.760178\tvalid_0's multi_logloss: 1.90153\tvalid_0's multi_error: 0.786133\n[160]\ttraining's multi_logloss: 1.87188\ttraining's multi_error: 0.75224\tvalid_0's multi_logloss: 1.89856\tvalid_0's multi_error: 0.783787\n[200]\ttraining's multi_logloss: 1.86361\ttraining's multi_error: 0.744868\tvalid_0's multi_logloss: 1.8966\tvalid_0's multi_error: 0.782\n[240]\ttraining's multi_logloss: 1.85606\ttraining's multi_error: 0.738409\tvalid_0's multi_logloss: 1.89511\tvalid_0's multi_error: 0.780933\n[280]\ttraining's multi_logloss: 1.84906\ttraining's multi_error: 0.732345\tvalid_0's multi_logloss: 1.89405\tvalid_0's multi_error: 0.780147\n[320]\ttraining's multi_logloss: 1.84248\ttraining's multi_error: 0.726437\tvalid_0's multi_logloss: 1.89329\tvalid_0's multi_error: 0.779333\n[360]\ttraining's multi_logloss: 1.83614\ttraining's multi_error: 0.72097\tvalid_0's multi_logloss: 1.89261\tvalid_0's multi_error: 0.778987\n[400]\ttraining's multi_logloss: 1.82998\ttraining's multi_error: 0.715967\tvalid_0's multi_logloss: 1.89203\tvalid_0's multi_error: 0.779067\n[440]\ttraining's multi_logloss: 1.82401\ttraining's multi_error: 0.710723\tvalid_0's multi_logloss: 1.89157\tvalid_0's multi_error: 0.778413\n[480]\ttraining's multi_logloss: 1.81821\ttraining's multi_error: 0.70568\tvalid_0's multi_logloss: 1.89104\tvalid_0's multi_error: 0.77812\n[520]\ttraining's multi_logloss: 1.8125\ttraining's multi_error: 0.700674\tvalid_0's multi_logloss: 1.89063\tvalid_0's multi_error: 0.777133\n[560]\ttraining's multi_logloss: 1.80688\ttraining's multi_error: 0.695575\tvalid_0's multi_logloss: 1.89025\tvalid_0's multi_error: 0.777307\n[600]\ttraining's multi_logloss: 1.80142\ttraining's multi_error: 0.690778\tvalid_0's multi_logloss: 1.88996\tvalid_0's multi_error: 0.777333\n[640]\ttraining's multi_logloss: 1.79605\ttraining's multi_error: 0.685833\tvalid_0's multi_logloss: 1.88971\tvalid_0's multi_error: 0.77684\n[680]\ttraining's multi_logloss: 1.79072\ttraining's multi_error: 0.681231\tvalid_0's multi_logloss: 1.88946\tvalid_0's multi_error: 0.776773\n[720]\ttraining's multi_logloss: 1.78544\ttraining's multi_error: 0.676668\tvalid_0's multi_logloss: 1.88921\tvalid_0's multi_error: 0.77652\n[760]\ttraining's multi_logloss: 1.78038\ttraining's multi_error: 0.672062\tvalid_0's multi_logloss: 1.8891\tvalid_0's multi_error: 0.776133\n[800]\ttraining's multi_logloss: 1.77527\ttraining's multi_error: 0.667447\tvalid_0's multi_logloss: 1.8889\tvalid_0's multi_error: 0.776613\n[840]\ttraining's multi_logloss: 1.77032\ttraining's multi_error: 0.663031\tvalid_0's multi_logloss: 1.88877\tvalid_0's multi_error: 0.776693\nEarly stopping, best iteration is:\n[751]\ttraining's multi_logloss: 1.78149\ttraining's multi_error: 0.67299\tvalid_0's multi_logloss: 1.88911\tvalid_0's multi_error: 0.775893\n[Fold 4] Final log loss: 1.88911, Final error: 0.77589\nLightGBM Train MAP3: 0.4773316049382085\nLightGBM Validation MAP3: 0.3619088888888375\n\n[Fold 4 is finished.]\n\n\n\ntrain_idx is [     0      1      2 ... 749997 749998 749999], length is 675000\nval_idx is [    19     20     29 ... 749981 749984 749996], length is 75000\nTraining until validation scores don't improve for 100 rounds\n[40]\ttraining's multi_logloss: 1.9066\ttraining's multi_error: 0.780578\tvalid_0's multi_logloss: 1.9132\tvalid_0's multi_error: 0.792507\n[80]\ttraining's multi_logloss: 1.892\ttraining's multi_error: 0.769099\tvalid_0's multi_logloss: 1.90538\tvalid_0's multi_error: 0.788947\n[120]\ttraining's multi_logloss: 1.88122\ttraining's multi_error: 0.760154\tvalid_0's multi_logloss: 1.90126\tvalid_0's multi_error: 0.786067\n[160]\ttraining's multi_logloss: 1.8719\ttraining's multi_error: 0.752108\tvalid_0's multi_logloss: 1.89852\tvalid_0's multi_error: 0.785067\n[200]\ttraining's multi_logloss: 1.86365\ttraining's multi_error: 0.745039\tvalid_0's multi_logloss: 1.89649\tvalid_0's multi_error: 0.783693\n[240]\ttraining's multi_logloss: 1.85605\ttraining's multi_error: 0.738255\tvalid_0's multi_logloss: 1.89516\tvalid_0's multi_error: 0.782453\n[280]\ttraining's multi_logloss: 1.84905\ttraining's multi_error: 0.732089\tvalid_0's multi_logloss: 1.89418\tvalid_0's multi_error: 0.781333\n[320]\ttraining's multi_logloss: 1.84246\ttraining's multi_error: 0.72647\tvalid_0's multi_logloss: 1.89342\tvalid_0's multi_error: 0.78104\n[360]\ttraining's multi_logloss: 1.83617\ttraining's multi_error: 0.721319\tvalid_0's multi_logloss: 1.89274\tvalid_0's multi_error: 0.780547\n[400]\ttraining's multi_logloss: 1.83008\ttraining's multi_error: 0.716142\tvalid_0's multi_logloss: 1.89218\tvalid_0's multi_error: 0.7804\n[440]\ttraining's multi_logloss: 1.82409\ttraining's multi_error: 0.710455\tvalid_0's multi_logloss: 1.89171\tvalid_0's multi_error: 0.779907\n[480]\ttraining's multi_logloss: 1.81832\ttraining's multi_error: 0.705496\tvalid_0's multi_logloss: 1.89138\tvalid_0's multi_error: 0.779707\n[520]\ttraining's multi_logloss: 1.81264\ttraining's multi_error: 0.700487\tvalid_0's multi_logloss: 1.89095\tvalid_0's multi_error: 0.779627\n[560]\ttraining's multi_logloss: 1.80709\ttraining's multi_error: 0.695548\tvalid_0's multi_logloss: 1.89067\tvalid_0's multi_error: 0.779333\n[600]\ttraining's multi_logloss: 1.80158\ttraining's multi_error: 0.69068\tvalid_0's multi_logloss: 1.89035\tvalid_0's multi_error: 0.779467\n[640]\ttraining's multi_logloss: 1.79624\ttraining's multi_error: 0.686133\tvalid_0's multi_logloss: 1.89011\tvalid_0's multi_error: 0.7784\n[680]\ttraining's multi_logloss: 1.79096\ttraining's multi_error: 0.681513\tvalid_0's multi_logloss: 1.88987\tvalid_0's multi_error: 0.778573\n[720]\ttraining's multi_logloss: 1.78572\ttraining's multi_error: 0.676689\tvalid_0's multi_logloss: 1.88964\tvalid_0's multi_error: 0.778307\n[760]\ttraining's multi_logloss: 1.78064\ttraining's multi_error: 0.672043\tvalid_0's multi_logloss: 1.8894\tvalid_0's multi_error: 0.777693\n[800]\ttraining's multi_logloss: 1.77558\ttraining's multi_error: 0.667649\tvalid_0's multi_logloss: 1.88923\tvalid_0's multi_error: 0.777467\n[840]\ttraining's multi_logloss: 1.77059\ttraining's multi_error: 0.663422\tvalid_0's multi_logloss: 1.88911\tvalid_0's multi_error: 0.77732\n[Fold 5] Final log loss: 1.88932, Final error: 0.77699\nLightGBM Train MAP3: 0.4801935802468309\nLightGBM Validation MAP3: 0.361797777777729\n\n[Fold 5 is finished.]\n\n\n\ntrain_idx is [     0      1      2 ... 749997 749998 749999], length is 675000\nval_idx is [    11     25     36 ... 749988 749992 749994], length is 75000\nTraining until validation scores don't improve for 100 rounds\n[40]\ttraining's multi_logloss: 1.90653\ttraining's multi_error: 0.780207\tvalid_0's multi_logloss: 1.91341\tvalid_0's multi_error: 0.793867\n[80]\ttraining's multi_logloss: 1.89189\ttraining's multi_error: 0.769043\tvalid_0's multi_logloss: 1.90604\tvalid_0's multi_error: 0.788333\n[120]\ttraining's multi_logloss: 1.88105\ttraining's multi_error: 0.759601\tvalid_0's multi_logloss: 1.90212\tvalid_0's multi_error: 0.786213\n[160]\ttraining's multi_logloss: 1.87173\ttraining's multi_error: 0.751492\tvalid_0's multi_logloss: 1.89952\tvalid_0's multi_error: 0.78456\n[200]\ttraining's multi_logloss: 1.86341\ttraining's multi_error: 0.744665\tvalid_0's multi_logloss: 1.89769\tvalid_0's multi_error: 0.783213\n[240]\ttraining's multi_logloss: 1.85585\ttraining's multi_error: 0.738022\tvalid_0's multi_logloss: 1.89646\tvalid_0's multi_error: 0.7822\n[280]\ttraining's multi_logloss: 1.84882\ttraining's multi_error: 0.731807\tvalid_0's multi_logloss: 1.89546\tvalid_0's multi_error: 0.780933\n[320]\ttraining's multi_logloss: 1.84216\ttraining's multi_error: 0.726139\tvalid_0's multi_logloss: 1.89464\tvalid_0's multi_error: 0.780987\n[360]\ttraining's multi_logloss: 1.83573\ttraining's multi_error: 0.720462\tvalid_0's multi_logloss: 1.89396\tvalid_0's multi_error: 0.780573\n[400]\ttraining's multi_logloss: 1.82958\ttraining's multi_error: 0.71519\tvalid_0's multi_logloss: 1.89341\tvalid_0's multi_error: 0.77988\n[440]\ttraining's multi_logloss: 1.82363\ttraining's multi_error: 0.709908\tvalid_0's multi_logloss: 1.89293\tvalid_0's multi_error: 0.779213\n[480]\ttraining's multi_logloss: 1.81781\ttraining's multi_error: 0.705141\tvalid_0's multi_logloss: 1.89248\tvalid_0's multi_error: 0.779173\n[520]\ttraining's multi_logloss: 1.81207\ttraining's multi_error: 0.699978\tvalid_0's multi_logloss: 1.89219\tvalid_0's multi_error: 0.77944\n[560]\ttraining's multi_logloss: 1.80653\ttraining's multi_error: 0.695043\tvalid_0's multi_logloss: 1.89187\tvalid_0's multi_error: 0.778813\n[600]\ttraining's multi_logloss: 1.80115\ttraining's multi_error: 0.690305\tvalid_0's multi_logloss: 1.89157\tvalid_0's multi_error: 0.77856\n[640]\ttraining's multi_logloss: 1.7958\ttraining's multi_error: 0.685677\tvalid_0's multi_logloss: 1.89123\tvalid_0's multi_error: 0.778573\n[680]\ttraining's multi_logloss: 1.79054\ttraining's multi_error: 0.680804\tvalid_0's multi_logloss: 1.89097\tvalid_0's multi_error: 0.778213\n[720]\ttraining's multi_logloss: 1.78536\ttraining's multi_error: 0.67605\tvalid_0's multi_logloss: 1.89075\tvalid_0's multi_error: 0.778147\n[760]\ttraining's multi_logloss: 1.78025\ttraining's multi_error: 0.671646\tvalid_0's multi_logloss: 1.89051\tvalid_0's multi_error: 0.777107\n[800]\ttraining's multi_logloss: 1.77513\ttraining's multi_error: 0.667015\tvalid_0's multi_logloss: 1.8903\tvalid_0's multi_error: 0.777653\n[840]\ttraining's multi_logloss: 1.77012\ttraining's multi_error: 0.662376\tvalid_0's multi_logloss: 1.89012\tvalid_0's multi_error: 0.77784\nEarly stopping, best iteration is:\n[761]\ttraining's multi_logloss: 1.78012\ttraining's multi_error: 0.671492\tvalid_0's multi_logloss: 1.89051\tvalid_0's multi_error: 0.776973\n[Fold 6] Final log loss: 1.89051, Final error: 0.77697\nLightGBM Train MAP3: 0.4792313580246184\nLightGBM Validation MAP3: 0.360597777777727\n\n[Fold 6 is finished.]\n\n\n\ntrain_idx is [     1      2      3 ... 749996 749998 749999], length is 675000\nval_idx is [     0      7     10 ... 749953 749982 749997], length is 75000\nTraining until validation scores don't improve for 100 rounds\n[40]\ttraining's multi_logloss: 1.90647\ttraining's multi_error: 0.780347\tvalid_0's multi_logloss: 1.91412\tvalid_0's multi_error: 0.794173\n[80]\ttraining's multi_logloss: 1.89186\ttraining's multi_error: 0.769095\tvalid_0's multi_logloss: 1.90634\tvalid_0's multi_error: 0.789787\n[120]\ttraining's multi_logloss: 1.88104\ttraining's multi_error: 0.759532\tvalid_0's multi_logloss: 1.90247\tvalid_0's multi_error: 0.787213\n[160]\ttraining's multi_logloss: 1.87168\ttraining's multi_error: 0.751607\tvalid_0's multi_logloss: 1.89978\tvalid_0's multi_error: 0.785333\n[200]\ttraining's multi_logloss: 1.86335\ttraining's multi_error: 0.744185\tvalid_0's multi_logloss: 1.89778\tvalid_0's multi_error: 0.783707\n[240]\ttraining's multi_logloss: 1.85577\ttraining's multi_error: 0.737961\tvalid_0's multi_logloss: 1.89656\tvalid_0's multi_error: 0.783133\n[280]\ttraining's multi_logloss: 1.84874\ttraining's multi_error: 0.732154\tvalid_0's multi_logloss: 1.89559\tvalid_0's multi_error: 0.782293\n[320]\ttraining's multi_logloss: 1.84207\ttraining's multi_error: 0.726147\tvalid_0's multi_logloss: 1.89476\tvalid_0's multi_error: 0.781333\n[360]\ttraining's multi_logloss: 1.83571\ttraining's multi_error: 0.72093\tvalid_0's multi_logloss: 1.89407\tvalid_0's multi_error: 0.78036\n[400]\ttraining's multi_logloss: 1.82959\ttraining's multi_error: 0.715532\tvalid_0's multi_logloss: 1.89359\tvalid_0's multi_error: 0.78096\n[440]\ttraining's multi_logloss: 1.82361\ttraining's multi_error: 0.709975\tvalid_0's multi_logloss: 1.89318\tvalid_0's multi_error: 0.780173\n[480]\ttraining's multi_logloss: 1.81777\ttraining's multi_error: 0.704769\tvalid_0's multi_logloss: 1.89275\tvalid_0's multi_error: 0.779907\n[520]\ttraining's multi_logloss: 1.81211\ttraining's multi_error: 0.699824\tvalid_0's multi_logloss: 1.89233\tvalid_0's multi_error: 0.779813\n[560]\ttraining's multi_logloss: 1.80659\ttraining's multi_error: 0.695028\tvalid_0's multi_logloss: 1.89199\tvalid_0's multi_error: 0.77996\nEarly stopping, best iteration is:\n[466]\ttraining's multi_logloss: 1.81976\ttraining's multi_error: 0.706687\tvalid_0's multi_logloss: 1.89292\tvalid_0's multi_error: 0.779387\n[Fold 7] Final log loss: 1.89292, Final error: 0.77939\nLightGBM Train MAP3: 0.4408970370372039\nLightGBM Validation MAP3: 0.35979999999995155\n\n[Fold 7 is finished.]\n\n\n\ntrain_idx is [     0      1      2 ... 749997 749998 749999], length is 675000\nval_idx is [    12     13     21 ... 749942 749963 749974], length is 75000\nTraining until validation scores don't improve for 100 rounds\n[40]\ttraining's multi_logloss: 1.90652\ttraining's multi_error: 0.780246\tvalid_0's multi_logloss: 1.91343\tvalid_0's multi_error: 0.794987\n[80]\ttraining's multi_logloss: 1.89198\ttraining's multi_error: 0.769173\tvalid_0's multi_logloss: 1.90558\tvalid_0's multi_error: 0.789253\n[120]\ttraining's multi_logloss: 1.88118\ttraining's multi_error: 0.759887\tvalid_0's multi_logloss: 1.90142\tvalid_0's multi_error: 0.7864\n[160]\ttraining's multi_logloss: 1.87186\ttraining's multi_error: 0.751713\tvalid_0's multi_logloss: 1.89861\tvalid_0's multi_error: 0.784853\n[200]\ttraining's multi_logloss: 1.86357\ttraining's multi_error: 0.744785\tvalid_0's multi_logloss: 1.89663\tvalid_0's multi_error: 0.78328\n[240]\ttraining's multi_logloss: 1.85607\ttraining's multi_error: 0.738673\tvalid_0's multi_logloss: 1.89525\tvalid_0's multi_error: 0.782187\n[280]\ttraining's multi_logloss: 1.84902\ttraining's multi_error: 0.732744\tvalid_0's multi_logloss: 1.89425\tvalid_0's multi_error: 0.781893\n[320]\ttraining's multi_logloss: 1.8424\ttraining's multi_error: 0.726781\tvalid_0's multi_logloss: 1.89359\tvalid_0's multi_error: 0.781413\n[360]\ttraining's multi_logloss: 1.83606\ttraining's multi_error: 0.721345\tvalid_0's multi_logloss: 1.89285\tvalid_0's multi_error: 0.781107\n[400]\ttraining's multi_logloss: 1.82991\ttraining's multi_error: 0.716039\tvalid_0's multi_logloss: 1.89229\tvalid_0's multi_error: 0.780333\n[440]\ttraining's multi_logloss: 1.82397\ttraining's multi_error: 0.710972\tvalid_0's multi_logloss: 1.89189\tvalid_0's multi_error: 0.780347\n[480]\ttraining's multi_logloss: 1.81813\ttraining's multi_error: 0.705661\tvalid_0's multi_logloss: 1.89143\tvalid_0's multi_error: 0.78016\n[520]\ttraining's multi_logloss: 1.81242\ttraining's multi_error: 0.700459\tvalid_0's multi_logloss: 1.89105\tvalid_0's multi_error: 0.779053\n[560]\ttraining's multi_logloss: 1.80681\ttraining's multi_error: 0.695627\tvalid_0's multi_logloss: 1.89067\tvalid_0's multi_error: 0.779093\n[600]\ttraining's multi_logloss: 1.80134\ttraining's multi_error: 0.690627\tvalid_0's multi_logloss: 1.89037\tvalid_0's multi_error: 0.778413\n[640]\ttraining's multi_logloss: 1.79596\ttraining's multi_error: 0.68589\tvalid_0's multi_logloss: 1.89014\tvalid_0's multi_error: 0.7784\n[680]\ttraining's multi_logloss: 1.79072\ttraining's multi_error: 0.681239\tvalid_0's multi_logloss: 1.8899\tvalid_0's multi_error: 0.778693\n[720]\ttraining's multi_logloss: 1.78549\ttraining's multi_error: 0.676593\tvalid_0's multi_logloss: 1.88968\tvalid_0's multi_error: 0.778667\n[760]\ttraining's multi_logloss: 1.78036\ttraining's multi_error: 0.672167\tvalid_0's multi_logloss: 1.88949\tvalid_0's multi_error: 0.777867\n[800]\ttraining's multi_logloss: 1.7753\ttraining's multi_error: 0.66749\tvalid_0's multi_logloss: 1.88927\tvalid_0's multi_error: 0.778867\n[840]\ttraining's multi_logloss: 1.77029\ttraining's multi_error: 0.66292\tvalid_0's multi_logloss: 1.88907\tvalid_0's multi_error: 0.778333\nEarly stopping, best iteration is:\n[760]\ttraining's multi_logloss: 1.78036\ttraining's multi_error: 0.672167\tvalid_0's multi_logloss: 1.88949\tvalid_0's multi_error: 0.777867\n[Fold 8] Final log loss: 1.88949, Final error: 0.77787\nLightGBM Train MAP3: 0.4787049382715299\nLightGBM Validation MAP3: 0.3617488888888385\n\n[Fold 8 is finished.]\n\n\n\ntrain_idx is [     0      1      2 ... 749997 749998 749999], length is 675000\nval_idx is [    41     48     54 ... 749979 749989 749990], length is 75000\nTraining until validation scores don't improve for 100 rounds\n[40]\ttraining's multi_logloss: 1.90655\ttraining's multi_error: 0.779956\tvalid_0's multi_logloss: 1.91359\tvalid_0's multi_error: 0.793267\n[80]\ttraining's multi_logloss: 1.89192\ttraining's multi_error: 0.768781\tvalid_0's multi_logloss: 1.90581\tvalid_0's multi_error: 0.789987\n[120]\ttraining's multi_logloss: 1.88116\ttraining's multi_error: 0.759834\tvalid_0's multi_logloss: 1.90174\tvalid_0's multi_error: 0.786587\n[160]\ttraining's multi_logloss: 1.87184\ttraining's multi_error: 0.75184\tvalid_0's multi_logloss: 1.89887\tvalid_0's multi_error: 0.783773\n[200]\ttraining's multi_logloss: 1.86357\ttraining's multi_error: 0.744756\tvalid_0's multi_logloss: 1.89697\tvalid_0's multi_error: 0.78236\n[240]\ttraining's multi_logloss: 1.85598\ttraining's multi_error: 0.738153\tvalid_0's multi_logloss: 1.89575\tvalid_0's multi_error: 0.781307\n[280]\ttraining's multi_logloss: 1.84904\ttraining's multi_error: 0.732022\tvalid_0's multi_logloss: 1.89484\tvalid_0's multi_error: 0.78068\n[320]\ttraining's multi_logloss: 1.84236\ttraining's multi_error: 0.726037\tvalid_0's multi_logloss: 1.89397\tvalid_0's multi_error: 0.780253\n[360]\ttraining's multi_logloss: 1.83598\ttraining's multi_error: 0.720443\tvalid_0's multi_logloss: 1.89327\tvalid_0's multi_error: 0.779867\n[400]\ttraining's multi_logloss: 1.82985\ttraining's multi_error: 0.715135\tvalid_0's multi_logloss: 1.89272\tvalid_0's multi_error: 0.77956\n[440]\ttraining's multi_logloss: 1.82388\ttraining's multi_error: 0.709982\tvalid_0's multi_logloss: 1.8922\tvalid_0's multi_error: 0.779973\n[480]\ttraining's multi_logloss: 1.81809\ttraining's multi_error: 0.705219\tvalid_0's multi_logloss: 1.89183\tvalid_0's multi_error: 0.779133\n[520]\ttraining's multi_logloss: 1.81239\ttraining's multi_error: 0.700385\tvalid_0's multi_logloss: 1.89149\tvalid_0's multi_error: 0.778827\n[560]\ttraining's multi_logloss: 1.80681\ttraining's multi_error: 0.6954\tvalid_0's multi_logloss: 1.89122\tvalid_0's multi_error: 0.77828\n[600]\ttraining's multi_logloss: 1.80133\ttraining's multi_error: 0.690871\tvalid_0's multi_logloss: 1.89102\tvalid_0's multi_error: 0.77808\n[640]\ttraining's multi_logloss: 1.79592\ttraining's multi_error: 0.685976\tvalid_0's multi_logloss: 1.89075\tvalid_0's multi_error: 0.777867\n[680]\ttraining's multi_logloss: 1.79056\ttraining's multi_error: 0.680991\tvalid_0's multi_logloss: 1.89049\tvalid_0's multi_error: 0.77868\nEarly stopping, best iteration is:\n[607]\ttraining's multi_logloss: 1.80037\ttraining's multi_error: 0.690027\tvalid_0's multi_logloss: 1.89098\tvalid_0's multi_error: 0.777747\n[Fold 9] Final log loss: 1.89098, Final error: 0.77775\nLightGBM Train MAP3: 0.4594812345679452\nLightGBM Validation MAP3: 0.3607755555555072\n\n[Fold 9 is finished.]\n\n\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"test_pred_prob_all_folds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:56:45.735942Z","iopub.execute_input":"2025-06-27T00:56:45.736139Z","iopub.status.idle":"2025-06-27T00:56:45.744899Z","shell.execute_reply.started":"2025-06-27T00:56:45.736124Z","shell.execute_reply":"2025-06-27T00:56:45.744134Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[array([[0.16223715, 0.137015  , 0.14260705, ..., 0.150895  , 0.19916726,\n         0.10224164],\n        [0.13477861, 0.11544437, 0.24305221, ..., 0.13326829, 0.09253877,\n         0.10188432],\n        [0.20112987, 0.2069908 , 0.12394007, ..., 0.15094759, 0.0947308 ,\n         0.08566567],\n        ...,\n        [0.14504583, 0.15518899, 0.10366532, ..., 0.09501075, 0.20311401,\n         0.17912145],\n        [0.1927835 , 0.11264773, 0.19600557, ..., 0.17714675, 0.13133042,\n         0.11825348],\n        [0.16647117, 0.20749408, 0.18831078, ..., 0.12450297, 0.07670708,\n         0.09069463]]),\n array([[0.18486043, 0.12192047, 0.13293999, ..., 0.16337887, 0.18049501,\n         0.11059323],\n        [0.13345972, 0.12084406, 0.22629623, ..., 0.12350343, 0.09563509,\n         0.12770536],\n        [0.19070309, 0.22321553, 0.13250539, ..., 0.14737444, 0.08719093,\n         0.08259519],\n        ...,\n        [0.15226114, 0.14820596, 0.11499673, ..., 0.10117655, 0.18080441,\n         0.18829714],\n        [0.17647749, 0.11026486, 0.18337787, ..., 0.17559906, 0.13565077,\n         0.1215465 ],\n        [0.14781972, 0.20913599, 0.1949283 , ..., 0.1291382 , 0.07341949,\n         0.10078362]]),\n array([[0.17618421, 0.13644501, 0.13555824, ..., 0.16434259, 0.14320715,\n         0.12832381],\n        [0.11548137, 0.11332859, 0.24101009, ..., 0.11865732, 0.08753511,\n         0.14175597],\n        [0.18918872, 0.24110355, 0.12864294, ..., 0.14344122, 0.08277172,\n         0.09518758],\n        ...,\n        [0.17962868, 0.14102412, 0.10618824, ..., 0.09668089, 0.1771198 ,\n         0.15668664],\n        [0.19682423, 0.1057125 , 0.1956762 , ..., 0.15808104, 0.14771013,\n         0.11233791],\n        [0.15011736, 0.208198  , 0.20712342, ..., 0.10728428, 0.07328969,\n         0.10485159]]),\n array([[0.17551495, 0.14035939, 0.1422164 , ..., 0.1413277 , 0.16999278,\n         0.1173061 ],\n        [0.13503522, 0.11119923, 0.27822642, ..., 0.11932168, 0.07636499,\n         0.13448358],\n        [0.1851778 , 0.22241777, 0.13358872, ..., 0.15168768, 0.08526099,\n         0.1001632 ],\n        ...,\n        [0.15050225, 0.16500009, 0.1106556 , ..., 0.09440293, 0.18759166,\n         0.16702867],\n        [0.20341472, 0.10949678, 0.18849119, ..., 0.16709432, 0.12861874,\n         0.1195908 ],\n        [0.15915009, 0.20188359, 0.19880897, ..., 0.12078291, 0.07310916,\n         0.10435365]]),\n array([[0.18608217, 0.13949277, 0.13430765, ..., 0.16056784, 0.17279392,\n         0.09839739],\n        [0.12609239, 0.12403081, 0.25169809, ..., 0.11709154, 0.08670513,\n         0.1315356 ],\n        [0.19763853, 0.20196491, 0.13162361, ..., 0.14128241, 0.08845003,\n         0.10614989],\n        ...,\n        [0.16252274, 0.16595246, 0.12041427, ..., 0.09751281, 0.15592776,\n         0.17533512],\n        [0.19247481, 0.13554126, 0.18592447, ..., 0.15897123, 0.12973938,\n         0.09831262],\n        [0.14842038, 0.21807273, 0.20267051, ..., 0.12538895, 0.0808244 ,\n         0.08866038]]),\n array([[0.16506639, 0.12721342, 0.14057681, ..., 0.15421791, 0.20297365,\n         0.10894894],\n        [0.14025866, 0.10400168, 0.26329497, ..., 0.11665452, 0.0912829 ,\n         0.12081578],\n        [0.19522321, 0.20362734, 0.12324968, ..., 0.15658632, 0.09581418,\n         0.09304843],\n        ...,\n        [0.16341508, 0.16095251, 0.11165048, ..., 0.10281762, 0.17648876,\n         0.16350543],\n        [0.17504487, 0.1153281 , 0.17342616, ..., 0.17909735, 0.1333397 ,\n         0.12382515],\n        [0.15465473, 0.19949915, 0.20489931, ..., 0.12314383, 0.07577115,\n         0.103783  ]]),\n array([[0.16622269, 0.13046208, 0.12101002, ..., 0.18367931, 0.19503469,\n         0.09787209],\n        [0.1327234 , 0.11787367, 0.23961878, ..., 0.1215442 , 0.0894986 ,\n         0.13368137],\n        [0.2061707 , 0.20727906, 0.13596841, ..., 0.13998321, 0.08773171,\n         0.09173385],\n        ...,\n        [0.16120141, 0.15957656, 0.10303827, ..., 0.10620931, 0.1563568 ,\n         0.19203484],\n        [0.202411  , 0.11735441, 0.19963694, ..., 0.1659733 , 0.12451734,\n         0.11250577],\n        [0.15489914, 0.19743161, 0.21504168, ..., 0.11345226, 0.07851595,\n         0.10201624]]),\n array([[0.17867192, 0.13502538, 0.13564311, ..., 0.15611504, 0.16508621,\n         0.10902898],\n        [0.13006356, 0.11244805, 0.25658421, ..., 0.1282269 , 0.08908513,\n         0.11633576],\n        [0.20285623, 0.20874703, 0.12789238, ..., 0.1478767 , 0.08440035,\n         0.09462898],\n        ...,\n        [0.16955149, 0.15351349, 0.10748058, ..., 0.09957734, 0.18808281,\n         0.15599195],\n        [0.18810121, 0.11511439, 0.17596078, ..., 0.16799936, 0.12993634,\n         0.1295809 ],\n        [0.1558609 , 0.19476877, 0.19630413, ..., 0.12804601, 0.07474246,\n         0.11074688]]),\n array([[0.14524781, 0.13797997, 0.14337134, ..., 0.16919313, 0.17110818,\n         0.10804005],\n        [0.14186777, 0.13255173, 0.24028121, ..., 0.12663969, 0.08109025,\n         0.11178243],\n        [0.18353745, 0.20707941, 0.13451181, ..., 0.14451428, 0.08465868,\n         0.09627091],\n        ...,\n        [0.17501653, 0.15934247, 0.1091754 , ..., 0.09390397, 0.18338239,\n         0.16041095],\n        [0.18116028, 0.12866896, 0.18022146, ..., 0.15452256, 0.12898699,\n         0.13720222],\n        [0.15497053, 0.20201401, 0.19937649, ..., 0.11960278, 0.06594059,\n         0.10806051]]),\n array([[0.17043872, 0.14441535, 0.13743549, ..., 0.17064579, 0.16647131,\n         0.10587922],\n        [0.13186157, 0.116458  , 0.23782347, ..., 0.12756615, 0.10049875,\n         0.12300037],\n        [0.18260665, 0.2106111 , 0.129235  , ..., 0.1600466 , 0.08527051,\n         0.10701179],\n        ...,\n        [0.15938329, 0.15408957, 0.11666488, ..., 0.10133627, 0.17506846,\n         0.17144916],\n        [0.20401308, 0.11597605, 0.1710681 , ..., 0.15758766, 0.14038658,\n         0.12806315],\n        [0.15888115, 0.18574023, 0.22169377, ..., 0.11646523, 0.07369327,\n         0.10631602]])]"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"### Load and use pretrained LightGBM","metadata":{}},{"cell_type":"code","source":"# lgbm = lightgbm.Booster(model_file='LightGBM_xxxx.txt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:56:45.745603Z","iopub.execute_input":"2025-06-27T00:56:45.745832Z","iopub.status.idle":"2025-06-27T00:56:45.761110Z","shell.execute_reply.started":"2025-06-27T00:56:45.745799Z","shell.execute_reply":"2025-06-27T00:56:45.760434Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"### Create submission file","metadata":{}},{"cell_type":"code","source":"# probs = lgbm.predict_proba(extended_test_meta_features)\n\nprobs = kfold_avg_probs\ntop_predict = np.argsort(probs, axis=1)[:, -output_pred_num:][:, ::-1]\n\nsubmission = pd.DataFrame({\n    'id': test_df_src['id'].values,\n})\nsubmission[\"Fertilizer Name\"] = [\n    \" \".join(rf.classes_[row]) for row in top_predict\n]\n\nsubmission.to_csv('submission.csv', index=False)\nprint(submission)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:56:45.761811Z","iopub.execute_input":"2025-06-27T00:56:45.762015Z","iopub.status.idle":"2025-06-27T00:56:46.483812Z","shell.execute_reply.started":"2025-06-27T00:56:45.762000Z","shell.execute_reply":"2025-06-27T00:56:46.483088Z"}},"outputs":[{"name":"stdout","text":"            id             Fertilizer Name\n0       750000          DAP 10-26-26 28-28\n1       750001     17-17-17 20-20 10-26-26\n2       750002     14-35-14 10-26-26 28-28\n3       750003  14-35-14 10-26-26 17-17-17\n4       750004         20-20 10-26-26 Urea\n...        ...                         ...\n249995  999995     14-35-14 17-17-17 28-28\n249996  999996         Urea 20-20 14-35-14\n249997  999997           DAP Urea 10-26-26\n249998  999998     10-26-26 17-17-17 28-28\n249999  999999  17-17-17 14-35-14 10-26-26\n\n[250000 rows x 2 columns]\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"submission_timestamp = os.path.getmtime('submission.csv')\nprint(\"Last modified:\", datetime.fromtimestamp(submission_timestamp).strftime('%Y-%m-%d %H:%M:%S'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T01:05:57.102986Z","iopub.execute_input":"2025-06-27T01:05:57.103530Z","iopub.status.idle":"2025-06-27T01:05:57.107953Z","shell.execute_reply.started":"2025-06-27T01:05:57.103505Z","shell.execute_reply":"2025-06-27T01:05:57.107150Z"}},"outputs":[{"name":"stdout","text":"Last modified: 2025-06-27 00:56:46\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"rf.classes_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:56:46.490141Z","iopub.execute_input":"2025-06-27T00:56:46.490354Z","iopub.status.idle":"2025-06-27T00:56:46.504026Z","shell.execute_reply.started":"2025-06-27T00:56:46.490332Z","shell.execute_reply":"2025-06-27T00:56:46.503331Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array(['10-26-26', '14-35-14', '17-17-17', '20-20', '28-28', 'DAP',\n       'Urea'], dtype=object)"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"rf.feature_names_in_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:56:46.504739Z","iopub.execute_input":"2025-06-27T00:56:46.504966Z","iopub.status.idle":"2025-06-27T00:56:46.518655Z","shell.execute_reply.started":"2025-06-27T00:56:46.504942Z","shell.execute_reply":"2025-06-27T00:56:46.518042Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"array(['Crop Type', 'Humidity', 'Moisture', 'Nitrogen', 'Phosphorous',\n       'Potassium', 'Soil Type', 'Temparature'], dtype=object)"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"submission","metadata":{"papermill":{"duration":0.01602,"end_time":"2025-06-24T15:17:04.418254","exception":false,"start_time":"2025-06-24T15:17:04.402234","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:56:46.519319Z","iopub.execute_input":"2025-06-27T00:56:46.519585Z","iopub.status.idle":"2025-06-27T00:56:46.535176Z","shell.execute_reply.started":"2025-06-27T00:56:46.519560Z","shell.execute_reply":"2025-06-27T00:56:46.534509Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"            id             Fertilizer Name\n0       750000          DAP 10-26-26 28-28\n1       750001     17-17-17 20-20 10-26-26\n2       750002     14-35-14 10-26-26 28-28\n3       750003  14-35-14 10-26-26 17-17-17\n4       750004         20-20 10-26-26 Urea\n...        ...                         ...\n249995  999995     14-35-14 17-17-17 28-28\n249996  999996         Urea 20-20 14-35-14\n249997  999997           DAP Urea 10-26-26\n249998  999998     10-26-26 17-17-17 28-28\n249999  999999  17-17-17 14-35-14 10-26-26\n\n[250000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Fertilizer Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>750000</td>\n      <td>DAP 10-26-26 28-28</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>750001</td>\n      <td>17-17-17 20-20 10-26-26</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>750002</td>\n      <td>14-35-14 10-26-26 28-28</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>750003</td>\n      <td>14-35-14 10-26-26 17-17-17</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>750004</td>\n      <td>20-20 10-26-26 Urea</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>249995</th>\n      <td>999995</td>\n      <td>14-35-14 17-17-17 28-28</td>\n    </tr>\n    <tr>\n      <th>249996</th>\n      <td>999996</td>\n      <td>Urea 20-20 14-35-14</td>\n    </tr>\n    <tr>\n      <th>249997</th>\n      <td>999997</td>\n      <td>DAP Urea 10-26-26</td>\n    </tr>\n    <tr>\n      <th>249998</th>\n      <td>999998</td>\n      <td>10-26-26 17-17-17 28-28</td>\n    </tr>\n    <tr>\n      <th>249999</th>\n      <td>999999</td>\n      <td>17-17-17 14-35-14 10-26-26</td>\n    </tr>\n  </tbody>\n</table>\n<p>250000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":26}]}