{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91717,"databundleVersionId":12184666,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":1262.816715,"end_time":"2025-06-24T15:17:05.345229","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-06-24T14:56:02.528514","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ncwd = os.getcwd()\nprint(\"Current working directory is {}\".format(cwd))\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_validate, cross_val_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, log_loss\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import make_column_selector as selector\n\nfrom datetime import datetime\nimport joblib\n\nimport lightgbm as lgb\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":4.097805,"end_time":"2025-06-24T14:56:11.585016","exception":false,"start_time":"2025-06-24T14:56:07.487211","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data preprocessing","metadata":{"papermill":{"duration":0.004907,"end_time":"2025-06-24T14:56:11.596038","exception":false,"start_time":"2025-06-24T14:56:11.591131","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def sort_columns(df):\n    return df.sort_index(axis=1)\n\ndef describe_data(df):\n    ## Basic statistics\n    describe = df.describe(include='all')\n    info = df.info()  # Return None, print df.info() directly to console.\n    null_count = df.isnull().sum()\n    ## Unique values\n    unique_count = df.nunique()\n    sample_size = df.shape[0]\n    unique_ratio = unique_count / sample_size\n    ## print data descriptions\n    print(\"\\n====== df:\\n\")\n    print(df)\n    print(\"\\n====== describe:\\n\")\n    print(describe)\n    print(\"\\n======info: \\n\")\n    print(df.info())\n    print(\"\\n====== null_count: \\n\")\n    print(null_count)\n    print(\"\\n====== unique_count: \\n\")\n    print(unique_count)\n    print(\"\\n====== unique_ratio: \\n\")\n    print(unique_ratio)\n\n    data_description = {\n        \"describe\": describe,\n        \"info\": info,\n        \"null_count\": null_count,\n        \"unique_count\": unique_count,\n        \"sample_size\": sample_size,\n        \"unique_ratio\": unique_ratio\n    }\n    return data_description\n\ndef drop_columns(df, cols_to_drop):\n    df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n    return df   \n\ndef intersect_train_test_columns(train_df, test_df):\n    ## Find common columns between train and test\n    common_cols = train_df.columns.intersection(test_df.columns)\n    ## Keep only those columns\n    train_aligned = train_df[common_cols].copy()\n    test_aligned = test_df[common_cols].copy()\n    return train_aligned, test_aligned\n\n######\n## Don't ever use dummies for one-hot encoding. Big issue when doing online prediction with new data.\n## pd.get_dummies() will mess up the one-hot positions.\n## Use OneHotEncoder from scikit-learn instead.\n######\n# def category_to_onehot(df, **kwargs):\n#     return pd.get_dummies(df, **kwargs)\n\ndef transform_numeric_to_category(df):\n    for col in df.select_dtypes(include=['int64', 'float64']).columns:\n        df[col] = df[col].astype('category')\n    return df\n\ndef build_label_encoders(train_df):\n    '''\n    LabelEncoder is strictly meant for 1D arrays (i.e., one column at a time). \n    It doesn’t support fitting across a 2D DataFrame of multiple categorical columns\n    '''\n    cat_cols = train_df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n    encoders = dict()\n    for col in cat_cols:\n        le = LabelEncoder()\n        train_df[col] = train_df[col].astype(str)  # Ensure consistent type\n        le.fit(train_df[col])\n        encoders[col] = le\n    return encoders\n\ndef build_onehot_encoder(train_df):\n    cat_cols = train_df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n    encoder = ColumnTransformer(\n        transformers=[\n            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols)\n        ],\n        remainder='passthrough'\n    )\n    encoder.fit(train_df)\n    return encoder\n\ndef mapk(y_true, y_pred_probs, k=3, labels=None):\n    \"\"\"\n    Compute Mean Average Precision at K (MAP@k).\n\n    Parameters:\n    - y_true: array-like of shape (n_samples,) – true labels (can be str or int)\n    - y_pred_probs: array-like of shape (n_samples, n_classes) – predicted class probabilities\n    - k: int – number of top predictions to consider\n    - labels: list – ordered list of label names corresponding to columns in y_pred_probs\n\n    Returns:\n    - map_k: float – MAP@k score\n    \"\"\"\n    if labels is None:\n        raise ValueError(\"You must provide a list of label names in `labels` to map predicted indices to class names.\")\n\n    top_k_preds = np.argsort(-y_pred_probs, axis=1)[:, :k]  # Get top-k predicted indices\n    y_true = np.asarray(y_true)\n\n    score = 0.0\n    for i in range(len(y_true)):\n        true_label = y_true[i]\n        predicted_labels = [labels[idx] for idx in top_k_preds[i]]\n\n        if true_label in predicted_labels:\n            rank = predicted_labels.index(true_label)\n            score += 1.0 / (rank + 1)\n\n    return score / len(y_true)","metadata":{"papermill":{"duration":0.018318,"end_time":"2025-06-24T14:56:11.619595","exception":false,"start_time":"2025-06-24T14:56:11.601277","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Parameter settings\nlabels = [\"Fertilizer Name\"]\ntimestamp = datetime.now().strftime('%Y%m%d')\noutput_pred_num = 3\n\n# Read inputs\ntrain_df = pd.read_csv(\"../input/playground-series-s5e6/train.csv\")\ntrain_df_src = train_df.copy()\ntest_df = pd.read_csv(\"../input/playground-series-s5e6/test.csv\")\ntest_df_src = test_df.copy()\nsample_df = pd.read_csv(\"../input/playground-series-s5e6/sample_submission.csv\")\n","metadata":{"papermill":{"duration":1.646191,"end_time":"2025-06-24T14:56:13.269202","exception":false,"start_time":"2025-06-24T14:56:11.623011","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_df\n# test_df_src\nsample_df.iloc[0, 1]\n","metadata":{"papermill":{"duration":0.012205,"end_time":"2025-06-24T14:56:13.284606","exception":false,"start_time":"2025-06-24T14:56:13.272401","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df_src","metadata":{"papermill":{"duration":0.035839,"end_time":"2025-06-24T14:56:13.323836","exception":false,"start_time":"2025-06-24T14:56:13.287997","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"############\n## Data Cleaning\n############\n\n## Describe data\ntrain_df_description = describe_data(train_df)\n\n## Sort data (Ensuring pd.get_dummies() gives consistent orders on train and test data.)\ntrain_df = sort_columns(train_df)\ntest_df = sort_columns(test_df)\n\n## Drop columns\ncols_to_drop = [\"id\"]\ntrain_df = drop_columns(train_df, cols_to_drop)\ntest_df = drop_columns(test_df, cols_to_drop)\n\n## Split labels from training data\ntrain_feature_df = train_df.drop(columns=labels)\ntrain_label_df = train_df[labels]\n\n## Take the intersection of train and test features.\ntrain_feature_df, test_df = intersect_train_test_columns(train_feature_df, test_df)\n\n############\n## Feature Engineering\n############\n\n## Transform categorical features into label encoding.\nlabel_encoders = build_label_encoders(train_df.copy())\ntrain_encoded = train_feature_df.copy()\nfor col, le in label_encoders.items():\n    if col in train_encoded.columns:\n        train_encoded[col] = le.transform(train_encoded[col].astype(str))\n    else:\n        print(f\"Warning: Column '{col}' not found in train_encoded. Skipping...\")\n        \ntest_encoded = test_df.copy()\nfor col, le in label_encoders.items():\n    if col in test_encoded.columns:\n        test_encoded[col] = le.transform(test_encoded[col].astype(str))\n    else:\n        print(f\"Warning: Column '{col}' not found in test_encoded. Skipping...\")\n        \ntrain_label_encoded = train_label_df.copy()\nfor col in train_label_encoded.columns:\n    if col in label_encoders.keys():\n        train_label_encoded[col] = label_encoders[col].transform(train_label_encoded[col].astype(str))\n        print(f\"Train label column '{col}' is encoded with LabelEncoder.\")\n\n## Transform numerical features into categorical features.\ntrain_encoded = transform_numeric_to_category(train_encoded)\ntest_encoded = transform_numeric_to_category(test_encoded)   \n\n# ## Transform categorical features into one-hot encoding.\n# oh_encoder = build_onehot_encoder(train_feature_df)\n\n# train_encoded = pd.DataFrame(\n#     oh_encoder.transform(train_df),\n#     columns=oh_encoder.get_feature_names_out(),\n#     index=train_df.index\n# )\n# test_encoded = pd.DataFrame(\n#     oh_encoder.transform(test_df),\n#     columns=oh_encoder.get_feature_names_out(),\n#     index=test_df.index\n# )\n\n\n# train_encoded = train_encoded.iloc[:200,]\n# train_label_df = train_label_df.iloc[:200]","metadata":{"papermill":{"duration":2.623124,"end_time":"2025-06-24T14:56:15.950647","exception":false,"start_time":"2025-06-24T14:56:13.327523","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_label_df.values.ravel()","metadata":{"papermill":{"duration":0.012737,"end_time":"2025-06-24T14:56:15.967489","exception":false,"start_time":"2025-06-24T14:56:15.954752","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'train_encoded.info():\\n{train_encoded.info()}')\nprint(f'{train_encoded}')\nprint(f'test_encoded.info():{test_encoded.info()}')\nprint(f'{test_encoded}')\nprint(f'train_label_df.info():\\n{train_label_df.info()}')\nprint(f'{train_label_df}')","metadata":{"papermill":{"duration":0.135648,"end_time":"2025-06-24T14:56:16.107208","exception":false,"start_time":"2025-06-24T14:56:15.971560","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training and Testing","metadata":{}},{"cell_type":"code","source":"######\n## Train models with cross_val_score()\n######\n\n## Set parameters\nrf_model_args = {\n    'n_estimators': 100,\n    'criterion': \"gini\",\n    'max_depth': 6,\n    'min_samples_split': 20,\n    'min_samples_leaf': 10,\n    'random_state': 42,\n    'max_features': \"sqrt\",\n    'n_jobs': -1,\n    'oob_score':True,\n    'max_samples': 0.85,\n    'verbose': 1,\n}\n\nrf_fit_cv_args = dict()\n\nrf_cv_args = {\n    'cv': 10,\n    'scoring': [\"neg_log_loss\", 'accuracy'],\n    'n_jobs': -1,\n    'verbose': 1,\n    'fit_params': rf_fit_cv_args,\n    'return_train_score': True,\n}\n\nx_rf = train_encoded\ny_rf = train_label_df.values.ravel()\n\n## Training and validation\nrf = RandomForestClassifier(**rf_model_args)\nrf_cv_scores = cross_validate(rf, x_rf, y_rf, **rf_cv_args)\nrf_cv_avg_scores = dict()\nfor k, v in rf_cv_scores.items():\n    mean_val = np.mean(v)\n    rf_cv_avg_scores[k] = mean_val\nprint(f\"\\nMean CV Score:\\n{rf_cv_avg_scores}\")\nprint(f\"\\nAll Fold Scores:\\n{rf_cv_scores}\")\n\nrf.fit(x_rf, y_rf) # Train on the whole training set as the final model.\njoblib.dump(rf, f'/kaggle/working/RandomForest_{timestamp}.joblib')\n\n## Predict on training data\ntrain_preds = rf.predict(x_rf)\n\n## Model analytics\nimportances = dict(zip(rf.feature_names_in_, rf.feature_importances_))\nsorted_importances = dict(sorted(\n    zip(rf.feature_names_in_, rf.feature_importances_),\n    key=lambda x: x[1],\n    reverse=True\n))\n","metadata":{"papermill":{"duration":1237.695581,"end_time":"2025-06-24T15:16:53.807528","exception":false,"start_time":"2025-06-24T14:56:16.111947","status":"completed"},"tags":[],"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.444Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Load and use pretrained LightGBM","metadata":{}},{"cell_type":"code","source":"# rf = joblib.load('RandomForest_20240624T170312.joblib')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dict(sorted(\n    zip(rf.feature_names_in_, rf.feature_importances_),\n    key=lambda x: x[1],\n    reverse=True\n))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ######\n# ## Train models with KFold()\n# ######\n\n# kf = KFold(n_splits=10, shuffle=True, random_state=42)\n# rf = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n\n# fold = 1\n# for train_index, val_index in kf.split(train_encoded):\n#     X_train, X_val = train_encoded.iloc[train_index], train_encoded.iloc[val_index]\n#     y_train, y_val = train_label_df.values.ravel()[train_index], train_label_df.values.ravel()[val_index]\n    \n#     rf.fit(X_train, y_train)\n#     preds = rf.predict(X_val)\n#     acc = accuracy_score(y_val, preds)\n    \n#     print(f\"Fold {fold} Accuracy: {acc:.4f}\")\n#     fold += 1","metadata":{"papermill":{"duration":0.011294,"end_time":"2025-06-24T15:16:53.823314","exception":false,"start_time":"2025-06-24T15:16:53.812020","status":"completed"},"tags":[],"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.444Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"markdown","source":"### Single Label Prediction","metadata":{}},{"cell_type":"code","source":"# test_predict = rf.predict(test_encoded)\n# print(test_predict)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.444Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### MAP@5 Prediction","metadata":{}},{"cell_type":"code","source":"# probs = rf.predict_proba(test_encoded)\n\n# top_predict = np.argsort(probs, axis=1)[:, -output_pred_num:][:, ::-1]\n# submission = pd.DataFrame({\n#     'id': test_df_src['id'].values,\n# })\n# submission[\"Fertilizer Name\"] = [\n#     \" \".join(rf.classes_[row]) for row in top_predict\n# ]\n\n# submission.to_csv('submission.csv', index=False)\n# print(submission)\n","metadata":{"papermill":{"duration":10.569788,"end_time":"2025-06-24T15:17:04.397612","exception":false,"start_time":"2025-06-24T15:16:53.827824","status":"completed"},"tags":[],"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.444Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Meta-learner Prediction","metadata":{}},{"cell_type":"markdown","source":"#### Meta-learning feature creation","metadata":{}},{"cell_type":"code","source":"train_probs = rf.predict_proba(train_encoded)\ntest_probs = rf.predict_proba(test_encoded)\n\ntrain_meta_features = pd.DataFrame(\n    data=train_probs,\n    columns=rf.classes_\n)\n\ntest_meta_features = pd.DataFrame(\n    data=test_probs,\n    columns=rf.classes_\n)\n\ntop_num = None  # Natural numbers or None to take all.\ntop_features = list(sorted_importances.keys()) if top_num is None else list(sorted_importances.keys())[:top_num]\n\n\nextended_train_meta_features = pd.merge(train_encoded[top_features], train_meta_features, left_index=True, right_index=True, how=\"left\")\nextended_test_meta_features = pd.merge(test_encoded[top_features], test_meta_features, left_index=True, right_index=True, how=\"left\")\n\n# extended_train_meta_features = train_encoded\n# extended_test_meta_features = test_encoded\n\nextended_train_meta_features = sort_columns(extended_train_meta_features)\nextended_test_meta_features = sort_columns(extended_test_meta_features)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"extended_train_meta_features","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.444Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Define inputs","metadata":{}},{"cell_type":"code","source":"x_meta = extended_train_meta_features\ny_meta = train_label_df.values.ravel()\nprint(y_meta)\n\nlgbm_model_args = {\n    'objective': 'multiclass',\n    'num_class': 7,\n    'boosting_type': 'gbdt',\n    'n_estimators': 10000,\n    'early_stopping_round': 100,  # No effect, only for compatibility. Call early_stopping in fit directly.\n    'learning_rate': 0.03,\n    \"num_leaves\": 31,\n    'max_depth': 8,\n    'random_state': 42,\n    'reg_alpha': 1.0, \n    'reg_lambda': 1.0,\n    'device_type': 'gpu',\n    'verbosity': -1,\n}\n\nlgbm_fit_cv_args = {\n    # 'eval_set': [(x_valid, y_valid)],\n    # 'callbacks': [lgb.early_stopping(stopping_rounds=50)],  # Early stopping not supported in sklearn cross_validate().\n    'eval_metric': ['multi_logloss', 'multi_error'],  \n}\n\nlgbm_fit_custom_args = {\n    'eval_set': None,\n    'eval_metric': ['multi_logloss', 'multi_error'],\n    'callbacks':[\n        lgb.early_stopping(stopping_rounds=lgbm_model_args['early_stopping_round']),\n        lgb.log_evaluation(period=40)\n    ],\n}\n\nlgbm_cv_args = {\n    'cv': 10,\n    'n_jobs': -1,\n    'verbose': 2,\n    'fit_params': lgbm_fit_cv_args\n}\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.444Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Model with cross_validate","metadata":{}},{"cell_type":"code","source":"# lgbm = lgb.LGBMClassifier(**lgbm_model_args)\n# lgbm_cv_scores = cross_validate(lgbm, x_meta, y_meta, **lgbm_cv_args)\n# lgbm_cv_avg_scores = dict()\n# for k, v in lgbm_cv_scores.items():\n#     mean_val = np.mean(v)\n#     lgbm_cv_avg_scores[k] = mean_val\n# print(f\"\\nMean CV Score:\\n{lgbm_cv_avg_scores}\")\n# print(f\"\\nAll Fold Scores:\\n{lgbm_cv_scores}\")\n\n# lgbm.fit(x_meta, y_meta, **lgbm_fit_cv_args)\n# lgbm.booster_.save_model('/kaggle/working/LightGBM_{}.txt'.format(timestamp))\n\n# # Predict on training data\n# train_preds = lgbm.predict(x_meta)\n\n# # # Method 1: Using .score()\n# # train_accuracy = lgbm.score(x_meta, y_meta)\n\n# # Method 2: Using accuracy_score\n# train_accuracy = accuracy_score(y_meta, train_preds)\n# print(f\"Training Accuracy: {train_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#### Model with custom flow\n\nkfold_num = lgbm_cv_args['cv']\nkf = StratifiedKFold(n_splits=kfold_num, shuffle=True, random_state=42)\ntest_proba_pred_all_folds = list()\nbest_iters = dict()\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(x_meta, y_meta)):\n    print(f'train_idx is {train_idx}, length is {len(train_idx)}')\n    print(f'val_idx is {val_idx}, length is {len(val_idx)}')\n    lgbm = lgb.LGBMClassifier(**lgbm_model_args)\n    x_train, x_val = x_meta.iloc[train_idx], x_meta.iloc[val_idx]\n    y_train, y_val = y_meta[train_idx], y_meta[val_idx]\n    lgbm_fit_custom_args['eval_set'] = [\n        (x_val, y_val),\n        (x_train, y_train)\n    ]\n    # lgbm_fit_custom_args['eval_set'] = [(x_val, y_val)]\n    lgbm.fit(x_train, y_train, **lgbm_fit_custom_args)\n    lgbm_fit_custom_args['eval_set'] = None\n    lgbm.booster_.save_model('/kaggle/working/LightGBM_fold{}_{}.txt'.format(fold, timestamp))\n    # Model evaluation\n    best_iter = lgbm.best_iteration_\n    best_iters[fold] = best_iter\n    num_iteration = best_iter + 0\n    labels = lgbm._classes\n    \n    eval_result = lgbm.evals_result_\n    final_logloss = eval_result['valid_0']['multi_logloss'][best_iter - 1]\n    final_error = eval_result['valid_0']['multi_error'][best_iter - 1]\n    print(f\"[Fold {fold}] Final log loss: {final_logloss:.5f}, Final error: {final_error:.5f}\")\n    \n    pred_prob_train = lgbm.predict_proba(x_train, num_iteration=num_iteration)\n    pred_prob_val = lgbm.predict_proba(x_val, num_iteration=num_iteration)\n    pred_train = lgbm.predict(x_train, num_iteration=num_iteration)\n    pred_val = lgbm.predict(x_val, num_iteration=num_iteration)\n    print(\"LightGBM Train Accuracy:\", accuracy_score(y_train, pred_train))  \n    print(\"LightGBM Validation Accuracy:\", accuracy_score(y_val, pred_val)) \n    \n    mapk_train = mapk(y_train, pred_prob_train, k=3, labels=labels)\n    mapk_val = mapk(y_val, pred_prob_val, k=3, labels=labels)\n    print(\"LightGBM Train MAP3:\", mapk_train)\n    print(\"LightGBM Validation MAP3:\", mapk_val)\n    \n    # Make prediction\n    test_proba_pred_probs = lgbm.predict_proba(extended_test_meta_features, num_iteration=num_iteration)\n    test_proba_pred_all_folds.append(test_proba_pred_probs)\n    print(f\"\\n[Fold {fold} is finished.]\\n\\n\\n\")\n    break\n    \n# Shape: (n_folds, n_samples, n_classes)\nstacked_preds = np.stack(test_proba_pred_all_folds, axis=0)\n\n# Average across folds\nkfold_avg_probs = np.mean(stacked_preds, axis=0)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_proba_pred_probs","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.445Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Load and use pretrained LightGBM","metadata":{}},{"cell_type":"code","source":"# lgbm = lightgbm.Booster(model_file='LightGBM_xxxx.txt')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.445Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Create submission file","metadata":{}},{"cell_type":"code","source":"# probs = lgbm.predict_proba(extended_test_meta_features)\n\nprobs = kfold_avg_probs\ntop_predict = np.argsort(probs, axis=1)[:, -output_pred_num:][:, ::-1]\n\nsubmission = pd.DataFrame({\n    'id': test_df_src['id'].values,\n})\nsubmission[\"Fertilizer Name\"] = [\n    \" \".join(rf.classes_[row]) for row in top_predict\n]\n\nsubmission.to_csv('submission.csv', index=False)\nprint(submission)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_timestamp = os.path.getmtime('submission.csv')\nprint(\"Last modified:\", datetime.fromtimestamp(submission_timestamp).strftime('%Y-%m-%d %H:%M:%S'))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rf.classes_","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rf.feature_names_in_","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission","metadata":{"papermill":{"duration":0.01602,"end_time":"2025-06-24T15:17:04.418254","exception":false,"start_time":"2025-06-24T15:17:04.402234","status":"completed"},"tags":[],"trusted":true,"execution":{"execution_failed":"2025-06-26T18:31:02.445Z"}},"outputs":[],"execution_count":null}]}